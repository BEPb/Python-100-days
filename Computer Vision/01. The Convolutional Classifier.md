### The Convolutional Classifier
Добро пожаловать в компьютерное зрение!
Вы когда-нибудь хотели научить компьютер видеть? В этом курсе вы именно этим и будете заниматься!

В этом курсе вы:

- Используйте современные сети глубокого обучения для создания классификатора изображений с помощью Keras
- Создайте свою собственную свертку с многоразовыми блоками
- Изучите фундаментальные идеи, лежащие в основе извлечения визуальных признаков
- Овладейте искусством трансфертного обучения, чтобы улучшить свои модели
- Используйте увеличение данных, чтобы расширить свой набор данных
- Если вы прошли курс «Введение в глубокое обучение», вы будете знать все, что вам нужно для успеха.

А теперь приступим!

### Введение
Этот курс познакомит вас с фундаментальными идеями компьютерного зрения. Наша цель - узнать, как нейронная сеть 
может «понимать» естественное изображение достаточно хорошо, чтобы решать те же проблемы, что и человеческая 
зрительная система.

Нейронные сети, которые лучше всего справляются с этой задачей, называются сверточными нейронными сетями (иногда 
вместо этого мы говорим свертка или CNN). Свертка - это математическая операция, которая придает слоям свертки их 
уникальную структуру. В будущих уроках вы узнаете, почему эта структура так эффективна при решении задач 
компьютерного зрения.

Мы применим эти идеи к проблеме классификации изображений: можем ли мы научить компьютер, имея изображение, 
сообщать нам, что это за изображение? Возможно, вы видели приложения, которые могут определять вид растений по 
фотографии. Это классификатор изображений! В этом курсе вы узнаете, как создавать классификаторы изображений, столь 
же мощные, как те, которые используются в профессиональных приложениях.

Хотя наше внимание будет сосредоточено на классификации изображений, то, что вы узнаете в этом курсе, актуально для 
всех видов проблем компьютерного зрения. В конце вы будете готовы перейти к более продвинутым приложениям, таким 
как генеративные состязательные сети и сегментация изображений.

### Сверточный классификатор
Свертка, используемая для классификации изображений, состоит из двух частей: сверточной основы и плотной головки.
База используется для извлечения функций из изображения. Он состоит в основном из слоев, выполняющих операцию 
свертки, но часто включает и другие типы слоев. (Вы узнаете об этом на следующем уроке.)

Голова используется для определения класса изображения.  Он состоит в основном из плотных слоев (dense layers), но 
может включать и другие слои, такие как выпадение (dropout).

Что мы подразумеваем под визуальной особенностью? Элементом может быть линия, цвет, текстура, форма, узор или 
какая-то сложная комбинация.

### Обучение классификатора
Цель сети во время обучения - изучить две вещи:

- какие особенности извлекать из изображения (базы),
- какой класс сочетается с какими функциями (голова).

 В наши дни коннеты редко обучаются с нуля. Чаще мы повторно используем базу предварительно обученной модели. Затем  
 к предварительно натренированной базе прикрепляем необученную голову. Другими словами, мы повторно используем часть 
 сети, которая уже научилась: 
1. Извлекать объекты и присоединять к ним несколько новых слоев для изучения 
2. Классифицировать.  

## Присоединение новой головы к обученной базе.
Поскольку голова обычно состоит всего из нескольких плотных слоев, очень точные классификаторы могут быть созданы на 
основе относительно небольшого объема данных. 

Повторное использование предварительно обученной модели - это метод, известный как трансферное обучение. Он 
настолько эффективен, что в наши дни почти каждый классификатор изображений будет его использовать. 

Пример - обучение классификатора Convnet
На протяжении этого курса мы будем создавать классификаторы, которые попытаются решить следующую проблему: это 
изображение автомобиля или грузовика? В нашем наборе данных около 10 000 изображений различных автомобилей, 
примерно половин легковых и наполовину грузовых.

###Шаг 1 - Загрузите данные
Следующая скрытая ячейка импортирует некоторые библиотеки и настроит конвейер данных. У нас есть тренировочный сплит 
ds_train и валидационный сплит ds_valid.  

```python
# Imports
import os, warnings
import matplotlib.pyplot as plt
from matplotlib import gridspec

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

# Reproducability
def set_seed(seed=31415):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
set_seed(31415)

# Set Matplotlib defaults
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')
warnings.filterwarnings("ignore") # to clean up output cells


# Load training and validation sets
ds_train_ = image_dataset_from_directory(
    '../input/car-or-truck/train',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)
ds_valid_ = image_dataset_from_directory(
    '../input/car-or-truck/valid',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=False,
)

# Data Pipeline
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = (
    ds_train_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
ds_valid = (
    ds_valid_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)

import matplotlib.pyplot as plt
```
###Шаг 2 - Определите предварительно обученную базу
Наиболее часто используемый набор данных для предварительного обучения - ImageNet, большой набор данных многих видов 
естественных изображений. Keras включает множество моделей, предварительно обученных в ImageNet, в свой модуль 
приложений. Предварительно обученная модель, которую мы будем использовать, называется VGG16.  

```python
pretrained_base = tf.keras.models.load_model(
    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',
)
pretrained_base.trainable = False
```
### Шаг 3 - Прикрепите голову
Далее прикрепляем головку классификатора. В этом примере мы будем использовать слой скрытых единиц (первый плотный 
слой), за которым следует слой, чтобы преобразовать выходные данные в оценку вероятности для класса 1, Truck. Слой 
Flatten преобразует двумерные выходные данные основы в одномерные входные данные, необходимые для головы.  
```python
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    pretrained_base,
    layers.Flatten(),
    layers.Dense(6, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])
```
### Шаг 4 - Тренируйтесь
Наконец, давайте обучим модель. Поскольку это проблема двух классов, мы будем использовать двоичные версии 
кроссэнтропии и точности. Оптимизатор адама в целом работает хорошо, поэтому мы тоже его выберем. 
```python
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['binary_accuracy'],
)

history = model.fit(
    ds_train,
    validation_data=ds_valid,
    epochs=30,
    verbose=0,
)
```
При обучении нейронной сети всегда полезно изучить графики потерь и показателей. Объект истории содержит эту 
информацию в словаре history.history. Мы можем использовать Pandas, чтобы преобразовать этот словарь в фреймворк и 
построить его с помощью встроенного метода.  
```python
import pandas as pd

history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();
```
Вывод
В этом уроке мы узнали о структуре классификатора свертки: голова действует как классификатор поверх основы, которая 
выполняет извлечение признаков. 

По сути, голова - это обычный классификатор, как вы узнали во вводном курсе. Для функций он использует те функции, 
которые были извлечены базой. Это основная идея, лежащая в основе сверточных классификаторов: мы можем присоединить 
модуль, который выполняет проектирование функций, к самому классификатору.  

Это одно из больших преимуществ глубоких нейронных сетей перед традиционными моделями машинного обучения: при 
правильной структуре сети глубокая нейронная сеть может научиться разрабатывать функции, необходимые для решения ее 
проблемы.  

В следующих нескольких уроках мы рассмотрим, как сверточная база выполняет извлечение признаков. Затем вы узнаете, 
как применять эти идеи и создавать собственные классификаторы. 


