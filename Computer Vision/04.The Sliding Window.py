## The Sliding Window
# Введение¶
# В этих упражнениях вы изучите операции, которые используются в нескольких популярных архитектурах сверток для
# извлечения признаков, узнаете о том, как свертки могут захватывать крупномасштабные визуальные объекты посредством
# наложения слоев, и, наконец, увидите, как свертку можно использовать для одномерных данных. в данном случае -
# временной ряд.
#
# Setup feedback system
from learntools.core import binder
binder.bind(globals())
from learntools.computer_vision.ex4 import *

import tensorflow as tf
import matplotlib.pyplot as plt
import learntools.computer_vision.visiontools as visiontools


plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')

# (Необязательно) Поэкспериментируйте с извлечением признаков
# Это упражнение предназначено для того, чтобы дать вам возможность изучить вычисления со скользящим окном и то,
# как их параметры влияют на извлечение признаков. Нет правильных или неправильных ответов - это просто шанс
# поэкспериментировать!
#
# Мы предоставили вам несколько изображений и ядер, которые вы можете использовать. Запустите эту ячейку,
# чтобы увидеть их.

from learntools.computer_vision.visiontools import edge, blur, bottom_sobel, emboss, sharpen, circle

image_dir = '../input/computer-vision-resources/'
circle_64 = tf.expand_dims(circle([64, 64], val=1.0, r_shrink=4), axis=-1)
kaggle_k = visiontools.read_image(image_dir + str('k.jpg'), channels=1)
car = visiontools.read_image(image_dir + str('car_illus.jpg'), channels=1)
car = tf.image.resize(car, size=[200, 200])
images = [(circle_64, "circle_64"), (kaggle_k, "kaggle_k"), (car, "car")]

plt.figure(figsize=(14, 4))
for i, (img, title) in enumerate(images):
    plt.subplot(1, len(images), i+1)
    plt.imshow(tf.squeeze(img))
    plt.axis('off')
    plt.title(title)
plt.show();

kernels = [(edge, "edge"), (blur, "blur"), (bottom_sobel, "bottom_sobel"),
           (emboss, "emboss"), (sharpen, "sharpen")]
plt.figure(figsize=(14, 4))
for i, (krn, title) in enumerate(kernels):
    plt.subplot(1, len(kernels), i+1)
    visiontools.show_kernel(krn, digits=2, text_size=20)
    plt.title(title)
plt.show()

# Воспринимающее поле
# Проследите все связи от какого-нибудь нейрона, и в конце концов вы дойдете до входного изображения. Все входные
# пиксели, к которым подключен нейрон, являются рецептивным полем этого нейрона. Рецептивное поле просто сообщает
# вам, из каких частей входного изображения нейрон получает информацию.
#
# Как мы видели, если ваш первый слой представляет собой свертку с ядрами 3 × 3, то каждый нейрон в этом слое
# получает входные данные из фрагмента пикселей 3 × 3 (за исключением, возможно, границы).
#
# Что произойдет, если вы добавите еще один сверточный слой с ядрами 3 × 3? Рассмотрим следующую иллюстрацию:
# Теперь проследите соединения от нейрона вверху, и вы увидите, что он подключен к участку 5 × 5 пикселей на входе (
# нижний слой): каждый нейрон на участке 3 × 3 в среднем слое подключен к Входной патч 3 × 3, но они перекрываются в
# патче 5 × 5. Итак, этот нейрон наверху имеет рецептивное поле 5 × 5.
#

# 1) Рост восприимчивого поля
# Теперь, если вы добавите третий сверточный слой с ядром (3, 3), какое рецептивное поле будет у его нейронов?
# Запустите ячейку ниже, чтобы получить ответ. (Или сначала посмотрите подсказку!)

# Так зачем складывать слои вот так? Три (3, 3) ядра имеют 27 параметров, в то время как одно (7, 7) ядро имеет 49,
# хотя оба они создают одно и то же рецептивное поле. Этот трюк с наложением слоев - один из способов,
# с помощью которого свертки могут создавать большие воспринимающие поля без чрезмерного увеличения количества
# параметров. В следующем уроке вы увидите, как это сделать самостоятельно!
#

# (Необязательно) Одномерная свертка
# Сверточные сети оказываются полезными не только для (двухмерных) изображений, но и для таких вещей, как временные
# ряды (одномерные) и видео (трехмерные).
#
# Мы видели, как сверточные сети могут научиться извлекать особенности из (двумерных) изображений. Оказывается,
# свертки также могут научиться извлекать функции из таких вещей, как временные ряды (одномерные) и видео (трехмерные).
#
# В этом (необязательном) упражнении мы увидим, как выглядит свертка на временном ряду.
#
# Мы будем использовать временные ряды из Google Trends. Он измеряет популярность поискового запроса "машинное
# обучение" за несколько недель с 25 января 2015 г. по 15 января 2020 г.
import pandas as pd

# Load the time series as a Pandas dataframe
machinelearning = pd.read_csv(
    '../input/computer-vision-resources/machinelearning.csv',
    parse_dates=['Week'],
    index_col='Week',
)

machinelearning.plot();

# А что с ядрами? Изображения двухмерные, поэтому наши ядра представляли собой 2D-массивы. Временные ряды одномерны,
# так каким должно быть ядро? Одномерный массив! Вот некоторые ядра, которые иногда используются для данных временных
# рядов:

detrend = tf.constant([-1, 1], dtype=tf.float32)

average = tf.constant([0.2, 0.2, 0.2, 0.2, 0.2], dtype=tf.float32)

spencer = tf.constant([-3, -6, -5, 3, 21, 46, 67, 74, 67, 46, 32, 3, -5, -6, -3], dtype=tf.float32) / 320

# 435 / 5 000
# Результаты перевода
# Свертка последовательности работает так же, как свертка изображения. Разница лишь в том, что скользящее окно в
# последовательности движется только в одном направлении - слева направо - вместо двух направлений на изображении. И,
# как и раньше, выбранные функции зависят от схемы чисел в ядре.
#
# Можете ли вы догадаться, какие функции извлекают эти ядра? Раскомментируйте одно из ядер ниже и запустите ячейку,
# чтобы увидеть!

# UNCOMMENT ONE
kernel = detrend
# kernel = average
# kernel = spencer

# Reformat for TensorFlow
ts_data = machinelearning.to_numpy()
ts_data = tf.expand_dims(ts_data, axis=0)
ts_data = tf.cast(ts_data, dtype=tf.float32)
kern = tf.reshape(kernel, shape=(*kernel.shape, 1, 1))

ts_filter = tf.nn.conv1d(
    input=ts_data,
    filters=kern,
    stride=1,
    padding='VALID',
)

# Format as Pandas Series
machinelearning_filtered = pd.Series(tf.squeeze(ts_filter).numpy())

machinelearning_filtered.plot();


# Фактически, ядро детренда фильтрует изменения в ряду, в то время как среднее и спенсер являются «сглаживающими»,
# которые фильтруют низкочастотные компоненты в ряду.
#
# Если вы хотите предсказать будущую популярность поисковых запросов, вы можете обучить свёрточную сеть на временных
# рядах, подобных этому. Он попытался бы узнать, какие функции в этих сериях наиболее информативны для прогноза.
#
# Хотя свертки сами по себе не являются лучшим выбором для такого рода проблем, они часто включаются в другие модели
# для их возможностей извлечения признаков.



# Вывод
# На этом уроке мы завершаем обсуждение извлечения признаков. Надеюсь, завершив эти уроки, вы получили некоторое
# представление о том, как работает этот процесс и почему обычные варианты его реализации часто оказываются наилучшими.







