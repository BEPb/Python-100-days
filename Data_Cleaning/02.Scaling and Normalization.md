# Scaling and Normalization
В этой записной книжке мы рассмотрим, как масштабировать и нормализовать данные (и в чем разница между ними!).

### Давайте начнем!

Настройте нашу среду
Первое, что нам нужно сделать, это загрузить библиотеки, которые мы будем использовать.

```python
# modules we'll use
import pandas as pd
import numpy as np

# for Box-Cox Transformation
from scipy import stats

# for min_max scaling
from mlxtend.preprocessing import minmax_scaling

# plotting modules
import seaborn as sns
import matplotlib.pyplot as plt

# set seed for reproducibility
np.random.seed(0)
```

### Масштабирование и нормализация: в чем разница?
Одна из причин, по которой легко спутать масштабирование и нормализацию, заключается в том, что эти термины иногда 
используются взаимозаменяемо и, что еще больше запутывает, они очень похожи! В обоих случаях вы преобразовываете 
значения числовых переменных, чтобы преобразованные точки данных имели определенные полезные свойства. Разница в том,
что:

- при масштабировании вы меняете диапазон своих данных, а
- при нормализации вы меняете форму распределения ваших данных.
Поговорим немного подробнее о каждом из этих вариантов.

### Масштабирование
Это означает, что вы преобразуете свои данные, чтобы они соответствовали определенной шкале, например 0–100 или 0–1. 
Вы хотите масштабировать данные, когда используете методы, основанные на измерении расстояния между точками данных, 
такие как машины опорных векторов (SVM) или k-ближайшие соседи (KNN). В этих алгоритмах изменение «1» в любом 
числовом признаке имеет одинаковое значение.

Например, вы можете просматривать цены на некоторые товары как в иенах, так и в долларах США. Один доллар США стоит 
около 100 иен, но если вы не масштабируете свои цены, такие методы, как SVM или KNN, будут считать разницу в цене в 
1 иену столь же важной, как и разницу в 1 доллар США! Это явно не соответствует нашим представлениям о мире. С 
валютой вы можете конвертировать между валютами. Но что, если вы смотрите на что-то вроде роста и веса? Не совсем 
ясно, сколько фунтов должно равняться одному дюйму (или сколько килограммов должно равняться одному метру).

Масштабируя свои переменные, вы можете помочь сравнить разные переменные на равных. Чтобы уяснить, как выглядит 
масштабирование, давайте рассмотрим выдуманный пример. (Не волнуйтесь, в следующем упражнении мы будем работать с 
реальными данными!) 

```python
# generate 1000 data points randomly drawn from an exponential distribution
original_data = np.random.exponential(size=1000)

# mix-max scale the data between 0 and 1
scaled_data = minmax_scaling(original_data, columns=[0])

# plot both together to compare
fig, ax = plt.subplots(1, 2, figsize=(15, 3))
sns.histplot(original_data, ax=ax[0], kde=True, legend=False)
ax[0].set_title("Original Data")
sns.histplot(scaled_data, ax=ax[1], kde=True, legend=False)
ax[1].set_title("Scaled data")
plt.show()
```
Обратите внимание, что форма данных не изменилась, но вместо диапазона от 0 до 8 теперь он находится в диапазоне от 
0 до 1. 

### Нормализация
Масштабирование просто изменяет диапазон ваших данных. Нормализация является более радикальным преобразованием. Суть 
нормализации состоит в том, чтобы изменить ваши наблюдения так, чтобы их можно было описать как нормальное 
распределение.  

Нормальное распределение: также известное как «кривая колокола», это конкретное статистическое распределение, при 
котором примерно равные наблюдения находятся выше и ниже среднего, среднее и медиана одинаковы, и больше наблюдений 
ближе к среднему. Нормальное распределение также известно как распределение Гаусса.  

В общем, вы нормализуете свои данные, если собираетесь использовать технику машинного обучения или статистики, 
которая предполагает, что ваши данные нормально распределены. Некоторые примеры из них включают линейный 
дискриминантный анализ (LDA) и гауссовский наивный байесовский анализ. (Совет: любой метод, в названии которого есть 
слово «Гаусс», вероятно, предполагает нормальность.)   

Метод, который мы используем для нормализации, называется преобразованием Бокса-Кокса. Давайте быстро взглянем на то,
как выглядит нормализация некоторых данных: 
```python
# normalize the exponential data with boxcox
normalized_data = stats.boxcox(original_data)

# plot both together to compare
fig, ax=plt.subplots(1, 2, figsize=(15, 3))
sns.histplot(original_data, ax=ax[0], kde=True, legend=False)
ax[0].set_title("Original Data")
sns.histplot(normalized_data[0], ax=ax[1], kde=True, legend=False)
ax[1].set_title("Normalized data")
plt.show()
```
Обратите внимание, что форма наших данных изменилась. До нормализации он был почти Г-образным. Но после нормализации 
он больше похож на контур колокола (отсюда и «кривая колокола»). 


