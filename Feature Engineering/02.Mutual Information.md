Mutual Information (Взаимная информация)
###Вступление
Первое знакомство с новым набором данных иногда может показаться ошеломляющим. Вам могут быть представлены сотни 
или тысячи функций, даже без описания. С чего начать?

Отличный первый шаг - построить рейтинг с метрикой полезности функции, функцией, измеряющей связи между функцией и 
целью. Затем вы можете выбрать меньший набор наиболее полезных функций для первоначальной разработки и иметь больше 
уверенности в том, что ваше время будет потрачено не зря.

Используемая нами метрика называется «взаимная информация». Взаимная информация во многом похожа на корреляцию в 
том смысле, что она измеряет взаимосвязь между двумя величинами. Преимущество взаимной информации заключается в том,
что она может обнаруживать любые отношения, в то время как корреляция обнаруживает только линейные отношения.

Взаимная информация - отличный показатель общего назначения, который особенно полезен в начале разработки функции, 
когда вы еще не знаете, какую модель хотите использовать. Это:

- проста в использовании и интерпретации,
- вычислительно эффективный,
- теоретически обоснованный,
- устойчивы к переобучению, и,
- способен обнаружить любые отношения

###Взаимная информация и что она измеряет
Взаимная информация описывает отношения с точки зрения неопределенности. Взаимная информация - Mutual Information  
(MI) между двумя величинами - это мера того, насколько знание одной величины снижает неопределенность относительно 
другой. Если бы вы знали ценность функции, насколько бы вы были более уверены в ее цели?

Вот пример из данных Ames Housing. На рисунке показана взаимосвязь между внешним качеством дома и ценой, по которой 
он был продан. Каждая точка представляет собой дом.

Четыре категории ExterQual: удовлетворительное, типичное, хорошее, отличное. Диаграмма рассеяния SalePrice в каждой 
категории.
Знание внешнего качества дома снижает неопределенность в отношении его продажной цены.
Из рисунка видно, что знание значения ExterQual должно сделать вас более уверенным в соответствующей SalePrice - 
каждая категория ExterQual имеет тенденцию концентрировать SalePrice в пределах определенного диапазона. Взаимная 
информация, которую ExterQual имеет с SalePrice, представляет собой среднее снижение неопределенности в SalePrice 
по четырем значениям ExterQual. Так как, например, «Удовлетворительно» встречается реже, чем «Типичное», значение 
«Удовлетворительное» в рейтинге MI меньше.

(Техническое примечание: то, что мы называем неопределенностью, измеряется с помощью величины из теории информации, 
известной как «энтропия». Энтропия переменной примерно означает: «сколько вопросов типа« да »или« нет »вам 
понадобится, чтобы описать возникновение этой переменная, в среднем. "Чем больше вопросов вы задаете, тем более 
неуверенным вы должны быть относительно переменной. Взаимная информация - это то, на сколько вопросов вы ожидаете, 
что функция ответит о цели.)

###Интерпретация результатов взаимной информации
Наименьшая возможная взаимная информация между величинами - 0,0. Когда MI равен нулю, величины независимы: ни один 
из них ничего не может сказать вам о другом. И наоборот, теоретически нет верхней границы того, каким может быть ИМ.
На практике значения выше 2,0 или около того встречаются редко. (Взаимная информация - это логарифмическая величина,
поэтому она увеличивается очень медленно.)

Следующий рисунок даст вам представление о том, как значения MI соответствуют типу и степени связи функции с целью.
Слева: взаимная информация увеличивается по мере того, как зависимость между функцией и целью становится более 
тесной. Справа: взаимная информация может фиксировать любые ассоциации (не только линейные, например корреляционные).
Вот несколько вещей, которые следует помнить при применении взаимной информации:

MI может помочь вам понять относительный потенциал функции как предиктора цели, рассматриваемой сама по себе.
Функция может быть очень информативной при взаимодействии с другими функциями, но не так информативна сама по себе. 
MI не может обнаружить взаимодействия между функциями. Это одномерная метрика.
Фактическая полезность функции зависит от модели, с которой вы ее используете. Функция полезна только в том случае, 
если ее связь с целью является той, которую ваша модель может изучить. Тот факт, что функция имеет высокий 
показатель MI, не означает, что ваша модель сможет что-либо делать с этой информацией. Вам может потребоваться 
сначала преобразовать функцию, чтобы выявить связь.

Пример - Автомобили 1985 года.
Набор данных Automobile состоит из 193 автомобилей 1985 модельного года. Цель этого набора данных - предсказать 
цену автомобиля (цель) на основе 23 характеристик автомобиля, таких как марка, body_style и мощность. В этом 
примере мы ранжируем функции с помощью взаимной информации и исследуем результаты с помощью визуализации данных.

```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

plt.style.use("seaborn-whitegrid")

df = pd.read_csv("../input/fe-course-data/autos.csv")
df.head()
```

Алгоритм scikit-learn для MI обрабатывает дискретные функции иначе, чем непрерывные. Следовательно, вам нужно 
сказать, какие из них какие. Как показывает практика, все, что должно иметь dtype с плавающей запятой, не является 
дискретным. Категориальные элементы (объектный или категориальный dtype) можно рассматривать как дискретные, если 
им присвоить кодировку метки. (Вы можете просмотреть кодировки меток в нашем уроке категориальных переменных.)

```python
X = df.copy()
y = X.pop("price")

# Label encoding for categoricals
# Кодировка метки для категорий
for colname in X.select_dtypes("object"):
    X[colname], _ = X[colname].factorize()

# All discrete features should now have integer dtypes (double-check this before using MI!)
# Все дискретные функции теперь должны иметь целочисленные типы (дважды проверьте это перед использованием MI!)
discrete_features = X.dtypes == int
```
Scikit-learn имеет две метрики взаимной информации в своем модуле feature_selection: одну для целей с 
действительным значением (relative_info_regression) и одну для категориальных целей (duplic_info_classif). Наша 
цель, цена, соответствует действительности. Следующая ячейка вычисляет показатели MI для наших функций и помещает 
их в красивый фрейм данных.

```python
from sklearn.feature_selection import mutual_info_regression

def make_mi_scores(X, y, discrete_features):
    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)
    mi_scores = pd.Series(mi_scores, name="MI Scores", index=X.columns)
    mi_scores = mi_scores.sort_values(ascending=False)
    return mi_scores

mi_scores = make_mi_scores(X, y, discrete_features)
mi_scores[::3]  # show a few features with their MI scores
# показать несколько функций с их показателями MI
```

А теперь гистограмма для упрощения сравнения:

```python
def plot_mi_scores(scores):
    scores = scores.sort_values(ascending=True)
    width = np.arange(len(scores))
    ticks = list(scores.index)
    plt.barh(width, scores)
    plt.yticks(width, ticks)
    plt.title("Mutual Information Scores")


plt.figure(dpi=100, figsize=(8, 5))
plot_mi_scores(mi_scores)
```

Визуализация данных - отличное продолжение рейтинга полезности. Давайте подробнее рассмотрим пару из них.
Как и следовало ожидать, функция curb_weight с высокими показателями демонстрирует сильную связь с ценой, целью.

```sns.relplot(x="curb_weight", y="price", data=df);```

Функция fuel_type имеет довольно низкий показатель MI, но, как мы видим из рисунка, она четко разделяет две ценовые 
группы с разными тенденциями в рамках функции лошадиных сил. Это указывает на то, что fuel_type способствует 
эффекту взаимодействия и, в конце концов, может быть немаловажным. Прежде чем решить, что функция не важна по ее 
оценке MI, хорошо изучить любые возможные эффекты взаимодействия - знания предметной области могут дать здесь много 
рекомендаций.

```sns.lmplot(x="horsepower", y="price", hue="fuel_type", data=df);```

Визуализация данных - отличное дополнение к вашему набору инструментов для разработки функций. Наряду с 
показателями полезности, такими как взаимная информация, подобные визуализации могут помочь вам обнаружить важные 
взаимосвязи в ваших данных. Ознакомьтесь с нашим курсом по визуализации данных, чтобы узнать больше!

Твоя очередь
Оцените характеристики набора данных Ames Housing и выберите свой первый набор функций для начала разработки.