Intermediate Machine Learning
###Настраивать
Missing Values
В этом руководстве вы изучите три подхода к работе с отсутствующими значениями. Затем вы сравните эффективность 
этих подходов на реальном наборе данных.

###Вступление
Есть много способов, по которым в данных могут оказаться пропущенные значения. Например,

Дом с 2 спальнями не будет включать стоимость третьей спальни.
Респондент опроса может решить не делиться своим доходом.
Большинство библиотек машинного обучения (включая scikit-learn) выдают ошибку, если вы пытаетесь построить модель, 
используя данные с отсутствующими значениями. Поэтому вам нужно выбрать одну из следующих стратегий.

###Три подхода
####1) Простой вариант: отбросить столбцы с отсутствующими значениями
Самый простой вариант - удалить столбцы с пропущенными значениями.
Если большинство значений в отброшенных столбцах отсутствует, модель теряет доступ к большому количеству 
(потенциально полезной!) Информации при таком подходе. В качестве крайнего примера рассмотрим набор данных из 10 
000 строк, в котором в одном важном столбце отсутствует одна запись. При таком подходе столбец полностью отбрасывается!

####2) Лучший вариант: вменение
Вменение заполняет пропущенные значения некоторым числом. Например, мы можем ввести среднее значение по каждому столбцу.
Вмененное значение в большинстве случаев будет не совсем правильным, но обычно оно приводит к более точным моделям, 
чем если бы вы полностью отбросили столбец.

####3) Продолжение вменения
Вменение - стандартный подход, и он обычно хорошо работает. Однако условно исчисленные значения могут 
   систематически быть выше или ниже их фактических значений (которые не были собраны в наборе данных). Или строки 
   с пропущенными значениями могут быть уникальными иным образом. В этом случае ваша модель будет делать более 
точные  прогнозы, учитывая, какие значения изначально отсутствовали.
В этом подходе мы, как и раньше, вменяем недостающие значения. И, кроме того, для каждого столбца с отсутствующими 
записями в исходном наборе данных мы добавляем новый столбец, который показывает расположение вмененных записей.

В некоторых случаях это значительно улучшит результаты. В других случаях это совсем не помогает.

Пример
В этом примере мы будем работать с набором данных Melbourne Housing. Наша модель будет использовать такую информацию,
как количество комнат и размер земельного участка, чтобы спрогнозировать стоимость дома.

Мы не будем заострять внимание на этапе загрузки данных. Вместо этого вы можете представить, что находитесь в точке,
где у вас уже есть данные для обучения и проверки в X_train, X_valid, y_train и y_valid.

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Load the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Select target
y = data.Price

# To keep things simple, we'll use only numerical predictors
melb_predictors = data.drop(['Price'], axis=1)
X = melb_predictors.select_dtypes(exclude=['object'])

# Divide data into training and validation subsets
X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,
                                                      random_state=0)
```
Определите функцию для измерения качества каждого подхода
Мы определяем функцию score_dataset () для сравнения различных подходов к работе с пропущенными значениями. Эта 
функция сообщает о средней абсолютной ошибке (MAE) для модели случайного леса.

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# Function for comparing different approaches
def score_dataset(X_train, X_valid, y_train, y_valid):
    model = RandomForestRegressor(n_estimators=10, random_state=0)
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    return mean_absolute_error(y_valid, preds)
```
Оценка по подходу 1 (выпадающие столбцы с пропущенными значениями)
Поскольку мы работаем как с обучающими, так и с проверочными наборами, мы стараемся отбрасывать одни и те же 
столбцы в обоих DataFrames.
```python
# Get names of columns with missing values
cols_with_missing = [col for col in X_train.columns
                     if X_train[col].isnull().any()]

# Drop columns in training and validation data
reduced_X_train = X_train.drop(cols_with_missing, axis=1)
reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)

print("MAE from Approach 1 (Drop columns with missing values):")
print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))
```
Оценка по подходу 2 (вменение)
Затем мы используем SimpleImputer для замены отсутствующих значений средним значением по каждому столбцу.

Хотя это просто, заполнение среднего значения обычно выполняется достаточно хорошо (но это зависит от набора данных)
. Хотя статистики экспериментировали с более сложными способами определения вмененных значений (например, 
вмененного регрессионного исчисления), сложные стратегии обычно не дают дополнительных преимуществ, если вы 
вставляете результаты в сложные модели машинного обучения.

```python
from sklearn.impute import SimpleImputer

# Imputation
my_imputer = SimpleImputer()
imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))
imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))

# Imputation removed column names; put them back
imputed_X_train.columns = X_train.columns
imputed_X_valid.columns = X_valid.columns

print("MAE from Approach 2 (Imputation):")
print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))
```
Мы видим, что подход 2 имеет более низкую MAE, чем подход 1, поэтому подход 2 работает лучше с этим набором данных.

Оценка по подходу 3 (дополнение к вменению)
Затем мы вменяем недостающие значения, а также отслеживаем, какие значения были вменены.

```python
# Make copy to avoid changing original data (when imputing)
X_train_plus = X_train.copy()
X_valid_plus = X_valid.copy()

# Make new columns indicating what will be imputed
for col in cols_with_missing:
    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()
    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()

# Imputation
my_imputer = SimpleImputer()
imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))
imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))

# Imputation removed column names; put them back
imputed_X_train_plus.columns = X_train_plus.columns
imputed_X_valid_plus.columns = X_valid_plus.columns

print("MAE from Approach 3 (An Extension to Imputation):")
print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))
```
Как мы видим, подход 3 показал себя немного хуже, чем подход 2.

Итак, почему вменение оказалось лучше, чем удаление столбцов?
Обучающие данные имеют 10864 строки и 12 столбцов, из которых три столбца содержат недостающие данные. Для каждого  
столбца отсутствует менее половины записей. Таким образом, удаление столбцов удаляет много полезной информации,  и 
поэтому имеет смысл, что вменение будет работать лучше.
```python
# Shape of training data (num_rows, num_columns)
print(X_train.shape)

# Number of missing values in each column of training data
missing_val_count_by_column = (X_train.isnull().sum())
print(missing_val_count_by_column[missing_val_count_by_column > 0])
```
### Заключение
Как обычно, вменение пропущенных значений  (в подходе 2 и подходе 3) дало лучшие результаты по сравнению с тем, 
когда мы просто отбрасывали столбцы с пропущенными значениями (в подходе 1).















