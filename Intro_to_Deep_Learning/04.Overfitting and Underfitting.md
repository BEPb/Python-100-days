### Overfitting and Underfitting
Введение
Вспомните из примера в предыдущем уроке, что Keras будет хранить историю потерь при обучении и проверке за те эпохи, 
когда он обучает модель. В этом уроке мы узнаем, как интерпретировать эти кривые обучения и как мы можем 
использовать их для руководства при разработке модели. В частности, мы исследуем кривые обучения на предмет 
доказательств недостаточного или переобучения и рассмотрим несколько стратегий для их исправления.   

### Интерпретация кривых обучения
Вы можете думать об информации в обучающих данных как о двух видах: сигнал и шум. Сигнал - это часть, которая 
обобщает, часть, которая может помочь нашей модели делать прогнозы на основе новых данных. Шум - это та часть, 
которая относится только к обучающим данным; шум - это все случайные колебания, которые происходят из данных в 
реальном мире, или все случайные, неинформативные шаблоны, которые на самом деле не могут помочь модели делать 
прогнозы. Шум может показаться полезным, но на самом деле это не так.    

Мы обучаем модель, выбирая веса или параметры, которые минимизируют потери в обучающей выборке. Однако вы можете 
знать, что для точной оценки производительности модели нам необходимо оценить ее на новом наборе данных, данных 
проверки. (Вы можете ознакомиться с нашим уроком по проверке моделей во введении в машинное обучение.)  

Когда мы обучаем модель, мы строим график потерь на обучающем наборе, эпоха за эпохой. К этому мы также добавим 
график данных проверки. Эти графики мы называем кривыми обучения. Чтобы эффективно обучать модели глубокого обучения,
мы должны уметь их интерпретировать.  

### График потери обучения и проверки.
Потеря проверки дает оценку ожидаемой ошибки на невидимых данных.
Теперь потери при обучении уменьшатся либо когда модель изучает сигнал, либо когда она изучает шум. Но потеря 
валидации снизится только тогда, когда модель узнает сигнал. (Какой бы шум модель ни узнала из обучающей выборки, 
она не будет обобщена на новые данные.) Итак, когда модель изучает сигнал, обе кривые идут вниз, но когда она 
изучает шум, в кривых создается разрыв. Размер зазора говорит о том, сколько шума усвоила модель.   

В идеале мы должны создать модели, которые изучают весь сигнал и не учитывают шум. Этого практически никогда не 
будет. Вместо этого мы совершаем сделку. Мы можем заставить модель изучать больше сигналов за счет изучения большего 
количества шума. Пока сделка идет в нашу пользу, потери при проверке будут продолжать уменьшаться. Однако после 
определенного момента сделка может обернуться против нас, стоимость превышает прибыль, и потери при проверке начнут 
расти.    

Два графика. Слева линия через несколько точек данных с истинной параболой. Справа кривая проходит через каждую 
точку данных с точной параболой. 


### Недооснащение и переоснащение.
Этот компромисс указывает на то, что при обучении модели могут возникнуть две проблемы: недостаточно сигнала или 
слишком много шума. Недостаток обучающей выборки - это когда потери не так низки, как могли бы быть, потому что 
модель не усвоила достаточно сигнала. Переобучение обучающей выборки - это когда потери не так низки, как могли бы 
быть, потому что модель усвоила слишком много шума. Уловка для обучения моделей глубокого обучения заключается в 
нахождении наилучшего баланса между ними.    

Мы рассмотрим несколько способов получить больше сигнала из обучающих данных при уменьшении количества шума.

### Емкость
Возможности модели связаны с размером и сложностью паттернов, которые она способна выучить. Для нейронных сетей это 
во многом будет определяться тем, сколько в ней нейронов и как они связаны друг с другом. Если окажется, что ваша 
сеть не соответствует данным, вам следует попробовать увеличить ее пропускную способность.  

Вы можете увеличить пропускную способность сети, сделав ее шире (больше единиц к существующим слоям) или сделав ее 
глубже (добавив больше слоев). Более широким сетям легче изучить более линейные отношения, в то время как более 
глубокие сети предпочитают более нелинейные. Что лучше, зависит от набора данных.  
```python
model = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])

wider = keras.Sequential([
    layers.Dense(32, activation='relu'),
    layers.Dense(1),
])

deeper = keras.Sequential([
    layers.Dense(16, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(1),
])
```

В упражнении вы узнаете, как пропускная способность сети может повлиять на ее производительность.

### Ранняя остановка
Мы упоминали, что, когда модель слишком усердно обучается шуму, потеря валидации может начать увеличиваться во время 
обучения. Чтобы предотвратить это, мы можем просто остановить обучение, когда кажется, что потеря валидации больше 
не уменьшается. Такой способ прерывания тренировки называется преждевременной остановкой.  

График кривых обучения с ранней остановкой при минимальной потере валидации, недостаточной подгонкой слева от нее и 
переобучением справа. 
Мы сохраняем модель, в которой потеря валидации минимальна.
Как только мы обнаруживаем, что потери при проверке снова начинают расти, мы можем сбросить веса обратно до 
минимального значения. Это гарантирует, что модель не будет продолжать учиться шуму и переобучать данные.  

Обучение с ранней остановкой также означает, что мы меньше подвержены опасности преждевременного прекращения 
обучения до того, как сеть завершит сигнал обучения. Таким образом, помимо предотвращения переобучения из-за слишком 
долгой тренировки, раннее прекращение может также предотвратить недостаточную тренировку из-за недостаточной 
тренировки. Просто установите для ваших тренировок какое-то большое количество (больше, чем вам нужно), и ранняя 
остановка позаботится обо всем остальном.    

Добавление ранней остановки
В Keras мы включаем раннюю остановку в наше обучение с помощью обратного вызова. Обратный вызов - это просто функция,
которую вы хотите запускать время от времени, пока сеть обучается. Обратный вызов ранней остановки будет запускаться 
после каждой эпохи. (У Keras есть множество предопределенных полезных обратных вызовов, но вы также можете 
определить свои собственные.)   

```python
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True,
)
```
Эти параметры говорят: «Если потеря валидации не улучшилась по крайней мере на 0,001 по сравнению с предыдущими 20 
эпохами, то остановите обучение и оставьте лучшую модель, которую вы нашли». Иногда бывает трудно сказать, 
увеличиваются ли потери при проверке из-за переобучения или просто из-за случайного изменения партии. Параметры 
позволяют нам установить некоторые допуски, когда нужно остановиться.   

Как мы увидим в нашем примере, мы передадим этот обратный вызов методу fit вместе с потерями и оптимизатором.

Пример - обучение модели с ранней остановкой
Продолжим разработку модели из примера в предыдущем уроке. Мы увеличим пропускную способность этой сети, но также 
добавим обратный вызов для ранней остановки, чтобы предотвратить переоснащение. 

И снова подготовка данных.

```python
import pandas as pd
from IPython.display import display

red_wine = pd.read_csv('../input/dl-course-data/red-wine.csv')

# Create training and validation splits
df_train = red_wine.sample(frac=0.7, random_state=0)
df_valid = red_wine.drop(df_train.index)
display(df_train.head(4))

# Scale to [0, 1]
max_ = df_train.max(axis=0)
min_ = df_train.min(axis=0)
df_train = (df_train - min_) / (max_ - min_)
df_valid = (df_valid - min_) / (max_ - min_)

# Split features and target
X_train = df_train.drop('quality', axis=1)
X_valid = df_valid.drop('quality', axis=1)
y_train = df_train['quality']
y_valid = df_valid['quality']
```
Теперь увеличим емкость сети. Мы выберем довольно большую сеть, но полагаемся на обратный вызов, чтобы остановить 
обучение, как только потеря проверки покажет признаки увеличения. 

```python
from tensorflow import keras
from tensorflow.keras import layers, callbacks

early_stopping = callbacks.EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=20, # how many epochs to wait before stopping
    restore_best_weights=True,
)

model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=[11]),
    layers.Dense(512, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(1),
])
model.compile(
    optimizer='adam',
    loss='mae',
)
```
После определения обратного вызова добавьте его как подходящий аргумент (у вас может быть несколько, поэтому 
поместите его в список). При использовании ранней остановки выберите большое количество эпох, больше, чем вам нужно. 
```python
history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=256,
    epochs=500,
    callbacks=[early_stopping], # put your callbacks in a list
    verbose=0,  # turn off training log
)

history_df = pd.DataFrame(history.history)
history_df.loc[:, ['loss', 'val_loss']].plot();
print("Minimum validation loss: {}".format(history_df['val_loss'].min()))
```

И действительно, Керас прекратил тренировки задолго до полных 500 эпох!

