# Forecasting With Machine Learning

### Введение
На уроках 2 и 3 мы рассматривали прогнозирование как простую задачу регрессии со всеми нашими функциями, полученными 
из одного входного параметра, временного индекса. Мы могли бы легко создавать прогнозы на любое время в будущем, 
просто создавая желаемую тенденцию и сезонные характеристики.  

Однако когда мы добавили функции задержки в Уроке 4, природа проблемы изменилась. Функции задержки требуют, чтобы 
целевое значение с задержкой было известно на момент прогнозирования. Функция отставания 1 сдвигает временной ряд на 
1 шаг вперед, что означает, что вы можете прогнозировать на 1 шаг в будущее, но не на 2 шага.  

В Уроке 4 мы просто предполагали, что всегда можем генерировать задержки до периода, который мы хотели 
спрогнозировать (другими словами, каждый прогноз был только на один шаг вперед). Прогнозирование в реальном мире 
обычно требует большего, поэтому в этом уроке мы узнаем, как делать прогнозы для различных ситуаций.  

### Определение задачи прогнозирования
Прежде чем разрабатывать модель прогнозирования, необходимо установить две вещи:

- какая информация доступна на момент составления прогноза (характеристики) и,
- период времени, в течение которого вам требуются прогнозируемые значения (цель).
Источником прогноза является время, на которое вы делаете прогноз. Практически вы можете считать, что источником 
  прогноза является последний раз, для которого у вас есть обучающие данные для прогнозируемого времени. Все, вплоть 
  до происхождения, может быть использовано для создания функций.   

Горизонт прогноза — это время, на которое вы делаете прогноз. Мы часто описываем прогноз количеством временных шагов 
на его горизонте: скажем, прогноз «1 шаг» или «5 шагов». Горизонт прогноза описывает цель. 


Трехэтапный горизонт прогнозирования с двухэтапным опережением и четырьмя запаздывающими функциями. На рисунке 
показано, что было бы одной строкой обучающих данных — другими словами, данными для одного прогноза. 
Время между источником и горизонтом — это время упреждения (или иногда задержка) прогноза. Время упреждения прогноза 
описывается количеством шагов от источника до горизонта: скажем, прогноз «на 1 шаг вперед» или «на 3 шага вперед». 
На практике может оказаться необходимым, чтобы прогноз начинался на несколько шагов раньше источника из-за задержек 
в сборе или обработке данных.   

### Подготовка данных для прогнозирования
Чтобы прогнозировать временные ряды с помощью алгоритмов ML, нам нужно преобразовать ряды в кадр данных, который мы 
можем использовать с этими алгоритмами. (Если, конечно, вы не используете только детерминированные функции, такие 
как тенденция и сезонность.)  

Мы видели первую половину этого процесса в уроке 4, когда создавали набор функций из задержек. Вторая половина 
готовит цель. Как мы это делаем, зависит от задачи прогнозирования.  

Каждая строка в кадре данных представляет собой один прогноз. Временной индекс строки — первый раз в горизонте 
прогноза, но мы размещаем значения для всего горизонта в той же строке. Для многоэтапных прогнозов это означает, что 
нам требуется модель для получения нескольких выходных данных, по одному для каждого шага.  

```python
import numpy as np
import pandas as pd

N = 20
ts = pd.Series(
    np.arange(N),
    index=pd.period_range(start='2010', freq='A', periods=N, name='Year'),
    dtype=pd.Int8Dtype,
)

# Lag features
X = pd.DataFrame({
    'y_lag_2': ts.shift(2),
    'y_lag_3': ts.shift(3),
    'y_lag_4': ts.shift(4),
    'y_lag_5': ts.shift(5),
    'y_lag_6': ts.shift(6),    
})

# Multistep targets
y = pd.DataFrame({
    'y_step_3': ts.shift(-2),
    'y_step_2': ts.shift(-1),
    'y_step_1': ts,
})

data = pd.concat({'Targets': y, 'Features': X}, axis=1)

data.head(10).style.set_properties(['Targets'], **{'background-color': 'LavenderBlush'}) \
                   .set_properties(['Features'], **{'background-color': 'Lavender'})
```
```commandline
Особенности целей
 y_step_3 y_step_2 y_step_1 y_lag_2 y_lag_3 y_lag_4 y_lag_5 y_lag_6
Год
2010 2 1 0 нан нан нан нан нан
2011 3 2 1 нан нан нан нан нан
2012 4 3 2 0 нан нан нан нан
2013 5 4 3 1 0 нан нан нан
2014 6 5 4 2 1 0 нан нан
2015 7 6 5 3 2 1 0 нано
2016 8 7 6 4 3 2 1 0
2017 9 8 7 5 4 3 2 1
2018 10 9 8 6 5 4 3 2
2019 11 10 9 7 6 5 4 3
```
 
Вышеприведенное иллюстрирует, как будет подготовлен набор данных, аналогичный рисунку «Определение прогноза»: 
трехэтапная задача прогнозирования с двухэтапным опережением с использованием пяти запаздывающих функций. Исходный 
временной ряд — y_step_1. Пропущенные значения мы могли либо заполнить, либо опустить.  

### Многошаговые стратегии прогнозирования
Существует ряд стратегий для создания нескольких целевых шагов, необходимых для прогноза. Мы опишем четыре общие 
стратегии, каждая из которых имеет сильные и слабые стороны.  

### Многовыходная модель
Используйте модель, которая естественным образом производит несколько выходных данных. И линейная регрессия, и 
нейронные сети могут давать несколько результатов. Эта стратегия проста и эффективна, но применима не для каждого 
алгоритма, который вы захотите использовать. Например, XGBoost не может этого сделать.  


### Прямая стратегия
Обучите отдельную модель для каждого шага в горизонте: одна модель прогнозирует на 1 шаг вперед, другая — на 2 шага 
вперед и так далее. Прогнозирование на 1 шаг вперед — это другая проблема, чем прогнозирование на 2 шага вперед (и т.
д.), поэтому полезно использовать разные модели для прогнозов для каждого шага. Недостатком является то, что 
обучение большого количества моделей может быть дорогостоящим в вычислительном отношении.   


### Рекурсивная стратегия
Обучите одну одношаговую модель и используйте ее прогнозы для обновления функций задержки для следующего шага. С 
помощью рекурсивного метода мы передаем одноэтапный прогноз модели обратно в ту же модель, чтобы использовать ее в 
качестве функции задержки для следующего шага прогнозирования. Нам нужно обучить только одну модель, но поскольку 
ошибки будут распространяться от шага к шагу, прогнозы могут быть неточными на больших горизонтах.   


### Стратегия DirRec
Комбинация прямой и рекурсивной стратегий: обучайте модель для каждого шага и используйте прогнозы из предыдущих 
шагов в качестве новых признаков запаздывания. Шаг за шагом каждый  модель получает дополнительный ввод задержки. 
Поскольку каждая модель всегда имеет актуальный набор функций задержки, стратегия DirRec может фиксировать 
последовательную зависимость лучше, чем прямая, но она также может страдать от распространения ошибок, как и 
рекурсивная.   


### Пример — тенденции гриппа
В этом примере мы применим стратегии MultiOutput и Direct к данным Flu Trends из урока 4, на этот раз делая верные 
прогнозы на несколько недель после периода обучения. 

Мы определим нашу задачу прогнозирования так, чтобы она имела 8-недельный горизонт с 1-недельным опережением. 
Другими словами, мы будем прогнозировать случаи заболевания гриппом на восемь недель, начиная со следующей недели.  

Скрытая ячейка устанавливает пример и определяет вспомогательную функцию plot_multistep.

Сначала мы подготовим нашу целевую серию (еженедельные визиты в офис по поводу гриппа) для многоэтапного 
прогнозирования. Как только это будет сделано, обучение и прогнозирование станут очень простыми. 
```python
def make_lags(ts, lags, lead_time=1):
    return pd.concat(
        {
            f'y_lag_{i}': ts.shift(i)
            for i in range(lead_time, lags + lead_time)
        },
        axis=1)


# Four weeks of lag features
y = flu_trends.FluVisits.copy()
X = make_lags(y, lags=4).fillna(0.0)


def make_multistep_target(ts, steps):
    return pd.concat(
        {f'y_step_{i + 1}': ts.shift(-i)
         for i in range(steps)},
        axis=1)


# Eight-week forecast
y = make_multistep_target(y, steps=8).dropna()

# Shifting has created indexes that don't match. Only keep times for
# which we have both targets and features.
y, X = y.align(X, join='inner', axis=0)

```
### Многовыходная модель
Мы будем использовать линейную регрессию в качестве стратегии MultiOutput. Как только мы подготовим наши данные для 
нескольких выходных данных, обучение и прогнозирование будут такими же, как всегда. 
```python
# Create splits
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)

model = LinearRegression()
model.fit(X_train, y_train)

y_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns)
y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)
```
Помните, что многошаговая модель будет давать полный прогноз для каждого экземпляра, используемого в качестве 
входных данных. В тренировочном наборе 269 недель, а в тестовом наборе 90 недель, и теперь у нас есть 8-шаговый 
прогноз для каждой из этих недель.  

```python
train_rmse = mean_squared_error(y_train, y_fit, squared=False)
test_rmse = mean_squared_error(y_test, y_pred, squared=False)
print((f"Train RMSE: {train_rmse:.2f}\n" f"Test RMSE: {test_rmse:.2f}"))

palette = dict(palette='husl', n_colors=64)
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6))
ax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1)
ax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette)
_ = ax1.legend(['FluVisits (train)', 'Forecast'])
ax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2)
ax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette)
_ = ax2.legend(['FluVisits (test)', 'Forecast'])
```
```commandline
Поезд RMSE: 389,12
Среднеквадратичное значение ошибки теста: 582,33
```


### Прямая стратегия
XGBoost не может создавать несколько выходных данных для задач регрессии. Но, применяя стратегию прямого сокращения, 
мы по-прежнему можем использовать ее для создания многошаговых прогнозов. Это так же просто, как обернуть его 
MultiOutputRegressor от scikit-learn.  

```python
from sklearn.multioutput import MultiOutputRegressor

model = MultiOutputRegressor(XGBRegressor())
model.fit(X_train, y_train)

y_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns=y.columns)
y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)
```


XGBoost здесь явно переоснащает тренировочный набор. Но на тестовом наборе кажется, что он смог уловить некоторую 
динамику сезона гриппа лучше, чем модель линейной регрессии. Вероятно, было бы еще лучше с некоторой настройкой 
гиперпараметров.  

```python
train_rmse = mean_squared_error(y_train, y_fit, squared=False)
test_rmse = mean_squared_error(y_test, y_pred, squared=False)
print((f"Train RMSE: {train_rmse:.2f}\n" f"Test RMSE: {test_rmse:.2f}"))

palette = dict(palette='husl', n_colors=64)
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6))
ax1 = flu_trends.FluVisits[y_fit.index].plot(**plot_params, ax=ax1)
ax1 = plot_multistep(y_fit, ax=ax1, palette_kwargs=palette)
_ = ax1.legend(['FluVisits (train)', 'Forecast'])
ax2 = flu_trends.FluVisits[y_pred.index].plot(**plot_params, ax=ax2)
ax2 = plot_multistep(y_pred, ax=ax2, palette_kwargs=palette)
_ = ax2.legend(['FluVisits (test)', 'Forecast'])
```

```commandline
Поезд RMSE: 1,22
Среднеквадратичное значение ошибки теста: 526,45
```

Чтобы использовать стратегию DirRec, вам нужно всего лишь заменить MultiOutputRegressor другой оболочкой 
scikit-learn, RegressorChain. Рекурсивную стратегию нам нужно было бы закодировать самим. 

