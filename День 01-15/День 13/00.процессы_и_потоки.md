## Процессы и потоки

Компьютеры, которые мы используем сегодня, уже вступили в эру многопроцессорных или многоядерных процессоров, и все операционные системы, которые мы используем, являются операционными системами, которые поддерживают «многозадачность», что позволяет нам запускать несколько программ одновременно или разлагать Программа на несколько относительных независимых подзадач позволяет выполнять несколько подзадач одновременно, тем самым сокращая время выполнения программы, а также позволяя пользователям получить лучший опыт. Таким образом, независимо от того, какой язык программирования используется для разработки в настоящий момент, программистам должно быть одним из необходимых навыков, чтобы понять, что программа может выполнять несколько задач одновременно, что часто называют «параллельным программированием». Для этого нам нужно сначала обсудить две концепции: одна называется процессом, а другая - потоком.

### концепция

Процесс - это программа, выполняемая в операционной системе. Операционная система выделяет пространство для хранения в единицах процессов. Каждый процесс имеет собственное адресное пространство, стек данных и другие вспомогательные данные, используемые для отслеживания выполнения процесса. Операционная система управляет выполнение всех процессов., разумно распределять ресурсы под них. Процессы могут использовать fork или spawn для создания новых процессов для выполнения других задач, но новые процессы также имеют свое собственное независимое пространство памяти, поэтому совместное использование данных должно осуществляться с помощью механизма межпроцессного взаимодействия (IPC, Inter-Process Communication). Конкретные методы включают каналы, сигналы, сокеты, области разделяемой памяти и так далее.

Процесс также может иметь несколько параллельных потоков выполнения. Проще говоря, у него есть несколько исполнительных модулей, которые могут быть запланированы ЦП. Это так называемый поток. Поскольку потоки находятся в одном процессе, они могут использовать один и тот же контекст, поэтому по сравнению с процессами обмен информацией и обмен данными между потоками проще. Конечно, в одноядерной системе ЦП настоящий параллелизм невозможен, потому что в определенный момент есть только один поток, который может получить ЦП, а несколько потоков разделяют время выполнения ЦП. Само собой разумеется, что использование многопоточности для достижения параллельного программирования приносит пользу программе. Наиболее важным проявлением является повышение производительности программы и улучшение взаимодействия с пользователем. Практически все программное обеспечение, которое мы используем сегодня, использует технологию многопоточности, которая Может использоваться Система поставляется с инструментом мониторинга процессов (например, «Монитор активности» в macOS, «Диспетчер задач» в Windows) для проверки, как показано на рисунке ниже.


Конечно, многопоточность не лишена своего вреда.С точки зрения других процессов, многопоточные программы не подходят для других программ, потому что они занимают больше времени выполнения ЦП, а другие программы не могут получить достаточно времени выполнения ЦП; С одной стороны, с точки зрения разработчиков, написание и отладка многопоточных программ предъявляют более высокие требования к разработчикам и сложнее для новичков.

Python поддерживает как многопроцессорность, так и многопоточность, поэтому существует три основных способа использования Python для реализации параллельного программирования: многопроцессорность, многопоточность, многопроцессорность + многопоточность.


### Многопроцессорность в Python

Операционные системы Unix и Linux предоставляют fork()системные вызовы для создания процессов. Вызывающая fork()функция является родительским процессом, а дочерний процесс создается. Дочерний процесс является копией родительского процесса, но дочерний процесс имеет свой собственный PID. fork()Функция очень особенная, она будет возвращать дважды, родительский процесс может получить fork()PID дочернего процесса через возвращаемое значение функции, а возвращаемое значение в дочернем процессе всегда равно 0. Модуль Python os предоставляет fork()функции. Поскольку система Windows не fork()вызывает, для достижения кроссплатформенного многопроцессорного программирования вы можете использовать Processкласс модуля многопроцессорности для создания подпроцессов, и этот модуль также предоставляет более продвинутые пакеты, такие как пул процессов ( Pool) для процессы пакетного запуска , Queues ( Queue) и pipe ( Pipe) для межпроцессного взаимодействия .

Давайте воспользуемся примером загрузки файлов, чтобы проиллюстрировать разницу между использованием нескольких процессов и неиспользованием нескольких процессов.Для начала давайте взглянем на следующий код.


```Python
from random import randint
from time import time, sleep


def download_task(filename):
    print('开始下载%s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s下载完成! 耗费了%d秒' % (filename, time_to_download))


def main():
    start = time()
    download_task('Python从入门到住院.pdf')
    download_task('Peking Hot.avi')
    end = time()
    print('总共耗费了%.2f秒.' % (end - start))


if __name__ == '__main__':
    main()
```

Ниже приводится результат выполнения программы.

```Shell
Начните загрузку Python от входа до hospitalization.pdf ...
Python от поступления до госпитализации. Загрузка в формате PDF завершена ! Это заняло 6 секунд.
Начните скачивание Peking Hot.avi ...
Загрузка Peking Hot.avi завершена ! Прошло 7 секунд.
Всего на это ушло 13,01 секунды.
```

Как видно из приведенного выше примера, если код в программе может выполняться только немного по порядку, то даже если выполняются две несвязанные задачи загрузки, необходимо дождаться загрузки одного файла перед запуском следующей. скачать.Задача, очевидно, нецелесообразна и неэффективна. Затем мы используем многопроцессорный метод, чтобы поместить две задачи загрузки в разные процессы, код показан ниже.

```Python
from multiprocessing import Process
from os import getpid
from random import randint
from time import time, sleep


def download_task(filename):
    print('启动下载进程，进程号[%d].' % getpid())
    print('开始下载%s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s下载完成! 耗费了%d秒' % (filename, time_to_download))


def main():
    start = time()
    p1 = Process(target=download_task, args=('Python从入门到住院.pdf', ))
    p1.start()
    p2 = Process(target=download_task, args=('Peking Hot.avi', ))
    p2.start()
    p1.join()
    p2.join()
    end = time()
    print('总共耗费了%.2f秒.' % (end - start))


if __name__ == '__main__':
    main()
```

В приведенном выше коде мы Processсоздали объект процесса через класс и targetпередали функцию через параметры, чтобы указать код, который будет выполняться после запуска процесса, а ниже argsприводится кортеж, который представляет параметры, переданные в функцию. Метод Processобъекта startиспользуется для запуска процесса, а joinметод означает ожидание окончания процесса. Выполнение приведенного выше кода, очевидно, может обнаружить, что две задачи загрузки запускаются «одновременно», и время выполнения программы будет значительно сокращено, и оно больше не является суммой времени двух задач. Ниже приводится результат одного выполнения программы.

```Shell
启动下载进程，进程号[1530].
开始下载Python从入门到住院.pdf...
启动下载进程，进程号[1531].
开始下载Peking Hot.avi...
Peking Hot.avi下载完成! 耗费了7秒
Python从入门到住院.pdf下载完成! 耗费了10秒
总共耗费了10.01秒.
```

Мы также можем использовать классы и функции в модуле подпроцесса для создания и запуска подпроцесса, а затем связываться с подпроцессом через конвейер. Мы не будем здесь объяснять это содержимое. Заинтересованные читатели могут понять это знание самостоятельно. Далее мы сосредоточимся на том, как добиться связи между двумя процессами. Мы запускаем два процесса: один вывод Ping, один вывод Pong, два процесса выводят Ping и Pong всего 10. Звучит просто, но писать так было бы неправильно.

```Python
from multiprocessing import Process
from time import sleep

counter = 0


def sub_task(string):
    global counter
    while counter < 10:
        print(string, end='', flush=True)
        counter += 1
        sleep(0.01)

        
def main():
    Process(target=sub_task, args=('Ping', )).start()
    Process(target=sub_task, args=('Pong', )).start()


if __name__ == '__main__':
    main()
```

Выглядит нормально, но конечный результат таков, что каждый пинг и понг выводит 10, почему? Когда мы создаем процесс в программе, дочерний процесс копирует родительский процесс и все его структуры данных, каждый дочерний процесс имеет свое собственное независимое пространство памяти, что означает, что в двух дочерних процессах есть counterпеременная, поэтому результат также Это можно представить. Относительно простой способ решить эту проблему - использовать Queueкласс в модуле многопроцессорности , который представляет собой очередь, которая может совместно использоваться несколькими процессами. Нижний уровень реализуется через механизм конвейера и семафоров . Заинтересованные читатели могут попробовать это самостоятельно. .


### Многопоточность в Python

В ранней версии Python для реализации многопоточного программирования был представлен модуль потока (теперь он называется _thread). Однако этот модуль слишком низкоуровневый, и многие функции не предоставляются. Поэтому мы рекомендуем использовать модуль потоковой передачи для текущего многопоточная разработка.Модуль обеспечивает лучшую объектно-ориентированную инкапсуляцию для многопоточного программирования. Давайте только сейчас реализуем пример загрузки файла в многопоточном режиме.

```Python
from random import randint
from threading import Thread
from time import time, sleep


def download(filename):
    print('开始下载%s...' % filename)
    time_to_download = randint(5, 10)
    sleep(time_to_download)
    print('%s下载完成! 耗费了%d秒' % (filename, time_to_download))


def main():
    start = time()
    t1 = Thread(target=download, args=('Python从入门到住院.pdf',))
    t1.start()
    t2 = Thread(target=download, args=('Peking Hot.avi',))
    t2.start()
    t1.join()
    t2.join()
    end = time()
    print('总共耗费了%.3f秒' % (end - start))


if __name__ == '__main__':
    main()
```

Мы можем напрямую использовать Threadкласс модуля потоковой передачи для создания потоков, но мы говорили об очень важной концепции, называемой «наследование». Мы можем создавать новые классы из существующих классов, поэтому мы также можем Threadсоздавать собственные классы , наследуя классы. Класс потока, затем создать объект потока и запустить поток. Код показан ниже.

```Python
from random import randint
from threading import Thread
from time import time, sleep


class DownloadTask(Thread):

    def __init__(self, filename):
        super().__init__()
        self._filename = filename

    def run(self):
        print('开始下载%s...' % self._filename)
        time_to_download = randint(5, 10)
        sleep(time_to_download)
        print('%s下载完成! 耗费了%d秒' % (self._filename, time_to_download))


def main():
    start = time()
    t1 = DownloadTask('Python从入门到住院.pdf')
    t1.start()
    t2 = DownloadTask('Peking Hot.avi')
    t2.start()
    t1.join()
    t2.join()
    end = time()
    print('总共耗费了%.2f秒.' % (end - start))


if __name__ == '__main__':
    main()
```

Поскольку несколько потоков могут совместно использовать пространство памяти процесса, относительно просто реализовать связь между несколькими потоками.Самый простой способ, который может придумать каждый, - это установить глобальную переменную, и несколько потоков могут совместно использовать эту глобальную переменную. Но когда несколько потоков совместно используют одну и ту же переменную (мы обычно называем ее «ресурсом»), это может привести к неконтролируемым результатам, что приведет к сбою программы или даже к сбою. Если ресурс конкурирует за использование несколькими потоками, то мы обычно называем его «критическим ресурсом», и доступ к «критическому ресурсу» должен быть защищен, иначе ресурс будет в «хаотическом» состоянии. В следующем примере демонстрируется сценарий, в котором 100 потоков переводят деньги на один и тот же банковский счет (переводят 1 юань). В этом примере банковский счет является критическим ресурсом, и мы можем получить ошибки без результата защиты.

```Python
from time import sleep
from threading import Thread


class Account(object):

    def __init__(self):
        self._balance = 0

    def deposit(self, money):
        # 计算存款后的余额
        new_balance = self._balance + money
        # 模拟受理存款业务需要0.01秒的时间
        sleep(0.01)
        # 修改账户余额
        self._balance = new_balance

    @property
    def balance(self):
        return self._balance


class AddMoneyThread(Thread):

    def __init__(self, account, money):
        super().__init__()
        self._account = account
        self._money = money

    def run(self):
        self._account.deposit(self._money)


def main():
    account = Account()
    threads = []
    # 创建100个存款的线程向同一个账户中存钱
    for _ in range(100):
        t = AddMoneyThread(account, 1)
        threads.append(t)
        t.start()
    # 等所有存款的线程都执行完毕
    for t in threads:
        t.join()
    print('账户余额为: ￥%d元' % account.balance)


if __name__ == '__main__':
    main()
```

При запуске вышеуказанной программы результат удивителен: каждый из 100 потоков переводит 1 юань на счет, результат на самом деле намного меньше 100 юаней. Это происходит потому, что мы не защитили «критический ресурс» банковских счетов. Когда несколько потоков вносят деньги на счет одновременно, new_balance = self._balance + moneyэта строка кода будет выполняться вместе , и все балансы счетов, полученные несколькими потоками, будут начальными. состояние 0, поэтому 0операция +1 была выполнена выше, поэтому был получен неправильный результат. В этом случае «замок» может пригодиться. Мы можем защитить «критические ресурсы» с помощью «блокировок». Только потоки, получившие «блокировку», могут получить доступ к «критическим ресурсам», а другие потоки, которые не получили «блокировку», могут быть заблокированы только до тех пор, пока поток, имеющий Полученная «блокировка» снимается. С «блокировкой» другие потоки имеют возможность получить «блокировку» и затем получить доступ к защищенному «критическому ресурсу». Следующий код демонстрирует, как использовать «блокировку» для защиты операции банковского счета, чтобы получить правильный результат.

```Python
from time import sleep
from threading import Thread, Lock


class Account(object):

    def __init__(self):
        self._balance = 0
        self._lock = Lock()

    def deposit(self, money):
        # 先获取锁才能执行后续的代码
        self._lock.acquire()
        try:
            new_balance = self._balance + money
            sleep(0.01)
            self._balance = new_balance
        finally:
            # 在finally中执行释放锁的操作保证正常异常锁都能释放
            self._lock.release()

    @property
    def balance(self):
        return self._balance


class AddMoneyThread(Thread):

    def __init__(self, account, money):
        super().__init__()
        self._account = account
        self._money = money

    def run(self):
        self._account.deposit(self._money)


def main():
    account = Account()
    threads = []
    for _ in range(100):
        t = AddMoneyThread(account, 1)
        threads.append(t)
        t.start()
    for t in threads:
        t.join()
    print('账户余额为: ￥%d元' % account.balance)


if __name__ == '__main__':
    main()
```

Еще более прискорбно то, что многопоточность Python не использует преимущества многоядерных характеристик ЦП. Это можно подтвердить, запустив несколько потоков, выполняющих бесконечный цикл. Причина этого в том, что интерпретатор Python имеет «глобальную блокировку интерпретатора» (GIL). Перед выполнением любого потока необходимо получить блокировку GIL, а затем каждый раз, когда выполняется 100 байт кода, интерпретатор автоматически освобождает GIL. lock., позволить другим потокам иметь возможность выполняться, это историческая проблема, но даже в этом случае, как мы приводили пример ранее, использование многопоточности по-прежнему положительно с точки зрения повышения эффективности выполнения и улучшения взаимодействия с пользователем.

### Многопроцессорность или многопоточность

Независимо от того, является ли это многопроцессорным или многопоточным, если их количество велико, эффективность определенно не улучшится.Почему? Давайте проведем аналогию. Предположим, вы, к сожалению, готовитесь к вступительным экзаменам в старшую школу. Каждую ночь вам нужно выполнять 5 домашних заданий по китайскому, математике, английскому языку, физике и химии. Каждое домашнее задание занимает 1 час. Если вы сначала потратите 1 час на выполнение домашнего задания по китайскому языку, то после его выполнения потратите 1 час на домашнее задание по математике, чтобы вы выполнили все их одно за другим, а в целом это займет 5 часов. Этот метод называется однозадачным. модель. Если вы планируете переключиться на модель многозадачности, вы можете 1 минуту изучить китайский язык, затем переключиться на домашнее задание по математике, выполнить 1 минуту, затем переключиться на английский и т. Д. Если скорость переключения достаточно высока, этот метод будет выполнять с одноядерным процессором. Многозадачность такая же. С точки зрения наблюдателя, вы пишете 5 домашних заданий одновременно.

Однако за переключение домашнего задания приходится платить. Например, чтобы переключиться с китайского на математику, вы должны сначала очистить языковые книги и ручки на столе (это называется сохранением сцены), затем открыть учебник математики и найти компас и линейка (это называется подготовкой к новой среде)). Прежде чем вы начнете делать домашнее задание по математике. Операционная система одинакова при переключении процессов или потоков. Она должна сохранить текущую среду выполнения (состояние регистров ЦП, страницу памяти и т. Д.), А затем подготовить среду выполнения новой задачи (восстановить последнее состояние регистра, переключить Страницы памяти и т. Д.) До начала выполнения. Хотя этот процесс переключения происходит быстро, он также требует времени. Если одновременно выполняются тысячи задач, операционная система может быть в основном занята переключением задач, и на выполнение задач совсем не так много времени. Наиболее распространенная ситуация - жужжание жесткого диска, отсутствие окна ответить, и система находится в состоянии приостановки анимации. Следовательно, как только многозадачность достигает предела, это приведет к резкому падению производительности системы и, в конечном итоге, к сбою всех задач.

Второе соображение относительно того, следует ли использовать многозадачность, - это тип задачи, который можно разделить на вычислительно-интенсивные и с интенсивным вводом-выводом. Характерной чертой задач с интенсивными вычислениями является выполнение большого количества вычислений и использование ресурсов ЦП, таких как кодирование и декодирование видео или преобразование формата и т. Д. Эта задача зависит от вычислительной мощности ЦП. Хотя она также может быть выполнена с помощью многозадачности, Чем больше задача - Больше, чем больше времени затрачивается на переключение задач, тем ниже эффективность ЦП для выполнения задач. Вычислительные задачи в основном потребляют ресурсы ЦП. Эффективность выполнения таких задач с помощью языков сценариев, таких как Python, обычно очень низкая. Язык C является наиболее подходящим для таких задач. Ранее мы упоминали, что Python имеет встроенный код C / C ++. .. Механизмы.

Помимо задач, требующих большого объема вычислений, другие задачи, связанные с вводом-выводом сети и носителей, могут рассматриваться как задачи с интенсивным вводом-выводом. Этот тип задач характеризуется низким потреблением ресурсов ЦП, и большая часть времени ожидания операции ввода-вывода уже завершена. (потому что скорость ввода-вывода намного ниже скорости процессора и памяти). Для задач с интенсивным вводом-выводом, если вы начнете многозадачность, вы можете уменьшить время ожидания ввода-вывода и позволить ЦП работать эффективно. Существует большой класс задач, связанных с интенсивным вводом-выводом, включая сетевые приложения и веб-приложения, в которых мы скоро будем участвовать.

> Примечание. Приведенное выше содержание и примеры взяты из «Учебного пособия по Python» на официальном сайте Ляо Сюэфэна . Поскольку они придерживаются разных взглядов на некоторые моменты статьи автора, в текстовое описание исходного текста были внесены соответствующие изменения.

### Однопоточный + асинхронный ввод / вывод

Самым важным в улучшении операций ввода-вывода в современных операционных системах является поддержка асинхронного ввода-вывода. Если вы в полной мере используете поддержку асинхронного ввода-вывода, предоставляемую операционной системой, вы можете использовать однопроцессную однопоточную модель для выполнения многозадачности.Эта новая модель называется моделью, управляемой событиями. Nginx - это веб-сервер, поддерживающий асинхронный ввод-вывод. Он использует однопроцессную модель на одноядерном ЦП для эффективной поддержки многозадачности. На многоядерном ЦП вы можете запускать несколько процессов (число совпадает с числом ядер ЦП), полностью используя многоядерный ЦП. Серверные программы, разработанные с помощью Node.js, также используют этот рабочий режим, который также является популярным решением для параллельного программирования.

На языке Python модель программирования с одним потоком + асинхронным вводом-выводом называется сопрограммой. Благодаря поддержке сопрограммы можно писать эффективные многозадачные программы, основанные на событиях. Самым большим преимуществом сопрограмм является чрезвычайно высокая эффективность выполнения, поскольку переключение подпрограмм - это не переключение потоков, а управляется самой программой, поэтому нет накладных расходов на переключение потоков. Второе преимущество сопрограммы заключается в том, что она не требует многопоточного механизма блокировки, потому что существует только один поток и нет конфликта записи переменных одновременно. В сопрограмме общие ресурсы не нуждаются в быть заблокированным, и для оценки требуется только состояние, поэтому выполнение. Эффективность намного выше, чем многопоточность. Если вы хотите в полной мере использовать многоядерность ЦП, самый простой способ - это многопроцессорность + сопрограмма, которая не только полностью использует многоядерность, но и дает полную возможность продемонстрировать высокую эффективность сопрограммы. для получения чрезвычайно высокой производительности. Содержание этой области будет объяснено в последующих курсах.

### Приложения

#### Поместите трудоемкие задачи в потоки, чтобы улучшить взаимодействие с пользователем.

В интерфейсе, показанном ниже, есть две кнопки: «Загрузить» и «О программе». Загрузка файлов в Интернете займет 10 секунд, если вы нажмете кнопку «Загрузить» в спящем режиме. Если вы не используете «многопоточность». , мы будем. Было обнаружено, что при нажатии кнопки «Загрузить» другие части всей программы блокируются этой трудоемкой задачей и не могут быть выполнены. Это, очевидно, очень неприятно для пользователя. Код показан ниже.

```Python
import time
import tkinter
import tkinter.messagebox


def download():
    # 模拟下载任务需要花费10秒钟时间
    time.sleep(10)
    tkinter.messagebox.showinfo('提示', '下载完成!')


def show_about():
    tkinter.messagebox.showinfo('关于', '作者: 骆昊(v1.0)')


def main():
    top = tkinter.Tk()
    top.title('单线程')
    top.geometry('200x150')
    top.wm_attributes('-topmost', True)

    panel = tkinter.Frame(top)
    button1 = tkinter.Button(panel, text='下载', command=download)
    button1.pack(side='left')
    button2 = tkinter.Button(panel, text='关于', command=show_about)
    button2.pack(side='right')
    panel.pack(side='bottom')

    tkinter.mainloop()


if __name__ == '__main__':
    main()
```

Если вы используете многопоточность для помещения трудоемких задач в отдельный поток для выполнения, чтобы основной поток не был заблокирован трудоемкими задачами, то измененный код показан ниже.

```Python
import time
import tkinter
import tkinter.messagebox
from threading import Thread


def main():

    class DownloadTaskHandler(Thread):

        def run(self):
            time.sleep(10)
            tkinter.messagebox.showinfo('提示', '下载完成!')
            # 启用下载按钮
            button1.config(state=tkinter.NORMAL)

    def download():
        # 禁用下载按钮
        button1.config(state=tkinter.DISABLED)
        # 通过daemon参数将线程设置为守护线程(主程序退出就不再保留执行)
        # 在线程中处理耗时间的下载任务
        DownloadTaskHandler(daemon=True).start()

    def show_about():
        tkinter.messagebox.showinfo('关于', '作者: 骆昊(v1.0)')

    top = tkinter.Tk()
    top.title('单线程')
    top.geometry('200x150')
    top.wm_attributes('-topmost', 1)

    panel = tkinter.Frame(top)
    button1 = tkinter.Button(panel, text='下载', command=download)
    button1.pack(side='left')
    button2 = tkinter.Button(panel, text='关于', command=show_about)
    button2.pack(side='right')
    panel.pack(side='bottom')

    tkinter.mainloop()


if __name__ == '__main__':
    main()
```

####  Используйте несколько процессов, чтобы «разделять и побеждать» сложные задачи.

Давайте выполним трудоемкую задачу по суммированию 1 ~ 100000000. Эта задача очень проста и может быть решена с небольшим знанием циклов.Код показан ниже.


```Python
from time import time


def main():
    total = 0
    number_list = [x for x in range(1, 100000001)]
    start = time()
    for number in number_list:
        total += number
    print(total)
    end = time()
    print('Execution time: %.3fs' % (end - start))


if __name__ == '__main__':
    main()
```

В приведенном выше коде я намеренно создал контейнер списка и заполнил 100000000 чисел. Этот шаг на самом деле занимает много времени, поэтому ради справедливости, когда мы разбиваем эту задачу на 8 процессов для выполнения. В то время мы не рассматриваем время, затраченное на операцию нарезки списка в данный момент, но учитывается только время операции и комбинированный результат операции.Код выглядит следующим образом.

```Python
from multiprocessing import Process, Queue
from random import randint
from time import time


def task_handler(curr_list, result_queue):
    total = 0
    for number in curr_list:
        total += number
    result_queue.put(total)


def main():
    processes = []
    number_list = [x for x in range(1, 100000001)]
    result_queue = Queue()
    index = 0
    # 启动8个进程将数据切片后进行运算
    for _ in range(8):
        p = Process(target=task_handler,
                    args=(number_list[index:index + 12500000], result_queue))
        index += 12500000
        processes.append(p)
        p.start()
    # 开始记录所有进程执行完成花费的时间
    start = time()
    for p in processes:
        p.join()
    # 合并执行结果
    total = 0
    while not result_queue.empty():
        total += result_queue.get()
    print(total)
    end = time()
    print('Execution time: ', (end - start), 's', sep='')


if __name__ == '__main__':
    main()
```

Сравните результаты выполнения двух фрагментов кода (на MacBook, который я использую в настоящее время, приведенный выше код занимает около 6 секунд, тогда как следующий код занимает менее 1 секунды. Опять же, мы просто сравнили время расчета, не учитывая время, затрачиваемое на создание списка и операции нарезки) .После использования нескольких процессов достигается большее время выполнения ЦП и лучшее использование многоядерных характеристик ЦП, что значительно сокращает время выполнения программы и тем больше объем вычислений большой эффект более очевиден. Конечно, при желании вы можете развернуть несколько процессов на разных компьютерах для создания распределенного процесса. Конкретный метод заключается в том, чтобы предоставить общий доступ к объекту через сеть через multiprocessing.managersдиспетчер, предоставленный в модуле Queue(зарегистрируйтесь в сети, чтобы другие компьютеры могли доступ), эта часть контента также остается на усмотрение поисковых роботов.
