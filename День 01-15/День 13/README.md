[Вернуться на главную](https://github.com/BEPb/Python-100-days)


## Процессы и потоки

Компьютеры, которые мы используем сегодня, уже вступили в эру многопроцессорных или многоядерных процессоров, и все операционные системы, которые мы используем, являются операционными системами, которые поддерживают «многозадачность», что позволяет нам запускать несколько программ одновременно или разлагать Программа на несколько относительных независимых подзадач позволяет выполнять несколько подзадач одновременно, тем самым сокращая время выполнения программы, а также позволяя пользователям получить лучший опыт. Таким образом, независимо от того, какой язык программирования используется для разработки в настоящий момент, программистам должно быть одним из необходимых навыков, чтобы понять, что программа может выполнять несколько задач одновременно, что часто называют «параллельным программированием». Для этого нам нужно сначала обсудить две концепции: одна называется процессом, а другая - потоком.

### концепция

Процесс - это программа, выполняемая в операционной системе. Операционная система выделяет пространство для 
хранения в единицах процессов. Каждый процесс имеет собственное адресное пространство, стек данных и другие 
вспомогательные данные, используемые для отслеживания выполнения процесса. Операционная система управляет 
выполнением всех процессов, разумно распределяя ресурсы под них. Процессы могут использовать fork или spawn для 
создания новых процессов для выполнения других задач, но новые процессы также имеют свое собственное независимое 
пространство памяти, поэтому совместное использование данных должно осуществляться с помощью механизма 
межпроцессного взаимодействия (IPC, Inter-Process Communication). Конкретные методы включают каналы, сигналы, сокеты,
области разделяемой памяти и так далее.


Процесс также может иметь несколько параллельных потоков выполнения. Проще говоря, у него есть несколько 
исполнительных модулей, которые могут быть запланированы ЦП - это так называемый поток. Поскольку потоки находятся в 
одном процессе, они могут использовать один и тот же контекст, поэтому по сравнению с процессами обмен информацией 
и обмен данными между потоками проще. Конечно, в одноядерной системе ЦП настоящий параллелизм невозможен, потому 
что в определенный момент есть только один поток, который может получить ЦП, а несколько потоков разделяют время 
выполнения ЦП. Само собой разумеется, что использование многопоточности для достижения параллельного 
программирования приносит пользу программе. Наиболее важным проявлением является повышение производительности 
программы и улучшение взаимодействия с пользователем. Практически все программное обеспечение, которое мы 
используем сегодня, использует технологию многопоточности. Система поставляется с 
инструментом мониторинга процессов например, «Монитор активности» в macOS или «Диспетчер задач» в Windows.


Конечно, многопоточность не лишена своих недостатков. С точки зрения других процессов, многопоточные программы 
тормозит выполненние кода для других программ, потому что ресурс Вашего компьютера не безграничен, и выполнение 
многопоточных программ нагружает ЦП больше, нежели другие программы. С точки зрения разработчиков, написание и отладка 
многопоточных программ предъявляют более высокие требования к разработчикам и сложнее для новичков.

Python поддерживает как многопроцессорность, так и многопоточность, поэтому существует три основных способа 
использования Python для реализации параллельного программирования: многопроцессорность, многопоточность, 
многопроцессорность + многопоточность.

### Многопроцессорность в Python

Операционные системы Unix и Linux предоставляют fork() системные вызовы для создания процессов. Вызывающая fork()
функция является родительским процессом, а процесс который он создал называется дочерним процессом . Дочерний процесс 
является копией родительского процесса, но дочерний процесс имеет свой собственный PID fork(). Функция очень 
особенная, она будет возвращать дважды, родительский процесс может получить fork() PID дочернего процесса через 
возвращаемое значение функции, а возвращаемое значение в дочернем процессе всегда равно 0. Модуль Python os 
предоставляет fork() функции. Поскольку система Windows не  вызывает fork(), для достижения кроссплатформенного 
многопроцессорного программирования вы можете использовать Process класс модуля многопроцессорности для создания 
подпроцессов, и этот модуль также предоставляет более продвинутые пакеты, такие как пул процессов (Pool) для 
процесов пакетного запуска , Queues (Queue) и pipe (Pipe) для межпроцессного взаимодействия.

Давайте воспользуемся примером загрузки файлов, чтобы проиллюстрировать разницу между использованием нескольких 
процессов и неиспользованием нескольких процессов. Для начала давайте взглянем на следующий код.


```Python
"""
Python 3.9 Эта прогррама показывает (имитирует) выполнение нескольких последовательных задач загрузки,
идущих одна за одной. Иммитация потому, что на самом деле ничего не загружается, а время загрузки генерируется
случайно модулем  `random` функцией генерации целых чисел `randint`
Название файла '01.последовательная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

from random import randint  # подключаем функцию генерации целых чисел
from time import time, sleep  # подключаем модуль работы со временем


def download_task(filename):  # функция-имитация загрузки файла (на входе имя файла)
    print('Начать загрузку %s...' % filename)  # перед загрузкой выводим сообщение на экран
    time_to_download = randint(5, 10)  # генерация случайного числа от 5 до 10
    sleep(time_to_download)  # ждем это случайное время
    print('Загрузка завершена! Потребовалось %d секунд' % time_to_download)  # выводим сообщение с отображением времени


def main():  # главная функция
    start = time()  # учитываем время начала программы, значение присваеиваем переменной
    download_task('Django.pdf')  # запускаем функцию загрузки файла Django.pdf
    download_task('PyTorch.epub')  # запускаем функцию загрузки файла PyTorch.epub
    end = time()  # учитываем время конца программы, значение присваеиваем переменной
    print('Всего заняло% .2f секунд.' % (end - start))  # сообщение о окончании с вычислением общего времени загрузки


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию
```

Ниже приводится результат выполнения программы.

```Shell
Начните загрузку Python от входа до hospitalization.pdf ...
Python от поступления до госпитализации. Загрузка в формате PDF завершена ! Это заняло 6 секунд.
Начните скачивание Peking Hot.avi ...
Загрузка Peking Hot.avi завершена ! Прошло 7 секунд.
Всего на это ушло 13,01 секунды.
```

Как видно из приведенного выше примера, если код в программе может выполняться только последовательно один за 
одним по порядку, то даже если выполняются две несвязанные задачи загрузки, необходимо дождаться загрузки одного 
файла перед запуском следующего. Задача, очевидно, выполняется неэффективно имея значительно-большую вычислительную 
мощность компьютера. Теперь давайте используем многопроцессорный метод, чтобы поместить две задачи загрузки в 
разные процессы, код показан ниже.

```Python
from multiprocessing import Process  # подключаем модуль работы с процессами
from os import getpid  # подключаем модуль взять номер процесса операционной системы
from random import randint  # модуль генерации случайных чисел
from time import time, sleep  # модуль работы со временем


def download_task(filename):  # функция загрузки задания  (на входе аргумент - имя файла)
    print('Номер процесса [%d].' % getpid())  # выводим номер процесса
    print('Имя файла %s...' % filename)  # выводим имя файла
    time_to_download = randint(5, 10)  # генерируем случайное число от 5 до 10
    sleep(time_to_download)  # ожидаем это время
    print('%s загружен! За %d секунд' % (filename, time_to_download))    # выводим имя файла и время загрузки


def main():  # главная функция
    start = time()  # засекаем время начала выполнения работы
    p1 = Process(target=download_task, args=('Django.pdf', ))  # создаем переменную, отдельный процесс запускающий 
    # функцию загрузки файла (указываем в классе target)
    p1.start()  # запускаем этот процесс
    p2 = Process(target=download_task, args=('PyTorch.epub', ))  # создаем переменную, отдельный процесс запускающий 
    # функцию загрузки файла
    p2.start()  # запускаем этот процесс
    p1.join()  # ожидание окончания процесса
    p2.join()  # ожидание окончания процесса
    end = time()  # засекаем время конца выполнения работы
    print('Время выполнения составило %.2f секунд.' % (end - start))  # время выполнения 2-х процессов


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию
```

Выполнение приведенного выше кода показывает, что две задачи загрузки запускаются «одновременно», 
и общее время выполнения программы будет значительно сокращено, и оно больше не является суммой времени двух задач. 

Мы также можем использовать классы и функции в модуле подпроцесса для создания и запуска подпроцесса, а затем 
связываться с подпроцессом через конвейер. Далее мы сосредоточимся на том, как добиться связи между двумя 
процессами. Мы запускаем два процесса: один вывод Ping, один вывод Pong, два процесса выводят Ping и Pong всего 10. 
Звучит просто, но писать так было бы неправильно.

```Python
"""
Python 3.9 Используйте класс Process для создания нескольких процессов
Название файла '02.много_процесс.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

# Результат выполнения следующей программы может подтвердить, что родительский процесс скопировал процесс и его
# структуру данных при создании дочернего процесса
# Каждый процесс имеет собственное независимое пространство памяти, поэтому обмен данными между процессами может
# осуществляться только через IPC
import random   # подключаем функцию генерации целых чисел
from multiprocessing import Process, Queue, current_process  # работа с множеством процессов
from time import sleep  # функция ожидания


def sub_task(content, counts):  # функция выполнения задания (на входе 2 аргумента строка и число)
    print(f'PID: {current_process().pid}')  # выводим номер процесса
    counter = 0  # создаем переменную равную 0
    while counter < counts:  # цикл пока число меньше принятого аргумента (от 5 до 10 сгенир. ниже)
        counter += 1  # увеличиваем значение перемнной на 1
        print(f'{counter}: {content}')  # печать числа и строки
        sleep(0.01)  # время ожидания - сотая секунда


def main():  # главная функция
    number = random.randrange(5, 10)  # генерация случайного числа от 5 до 10 присваиваем переменной number
    Process(target=sub_task, args=('Ping', number)).start()  # создаем и запускаем процесс, указываем имя запускаемой
    # функции, а также передаваемые аргументы, строку и число
    Process(target=sub_task, args=('Pong', number)).start()  # создаем и запускаем процесс, указываем имя запускаемой
    # функции, а также передаваемые аргументы, строку и число


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию
```

### Многопоточность в Python

В ранней версии Python для реализации многопоточного программирования был представлен модуль потока (теперь он 
называется _thread). Однако этот модуль слишком низкоуровневый, и многие функции не предоставляются. Поэтому мы 
рекомендуем использовать модуль потоковой передачи для текущего процесса - многопоточная разработка. Модуль 
обеспечивает лучшую объектно-ориентированную инкапсуляцию для многопоточного программирования. Давайте только 
сейчас реализуем пример загрузки файла в многопоточном режиме.

```Python
"""
Python 3.9 При использовании многопоточности совершаем несколько задач загрузки
Название файла '03.16. многопоточная_загрузка.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""


from threading import Thread  # подключаем модуль многопоточной работы
from random import randint  # подключаем функцию генерации целых чисел
from time import time, sleep  # подключаем модуль работы со временем


def download_task(filename):  # функция-имитация загрузки файла (на входе имя файла)
    print('Начать загрузку %s...' % filename)  # перед загрузкой выводим сообщение на экран
    time_to_download = randint(5, 10)  # генерация случайного числа от 5 до 10
    sleep(time_to_download)  # ждем это случайное время
    print('Загрузка завершена! Потребовалось %d секунд' % time_to_download)  # выводим сообщение с отображением времени


def main():  # главная функция
    start = time()  # время начала выполнения программы
    thread1 = Thread(target=download_task, args=('Django.pdf',))  # создаем поток
    thread1.start()  # начало выполнения потока
    thread2 = Thread(target=download_task, args=('PyTorch.epub',))  # создаем поток
    thread2.start()  # начало выполнения потока
    thread1.join()  # ожидание выполнения
    thread2.join()  # ожидание выполнения
    end = time()  # время конца выполнения программы
    print('Всего потребовалось %.3f секунд..' % (end - start))  # сообщение о окончании с вычислением общего времени загрузки


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию

```

Мы можем напрямую использовать Thread класс модуля потоковой передачи для создания потоков, но мы говорили об очень 
важной концепции, называемой «наследование». Мы можем создавать новые классы из существующих классов, поэтому мы 
также можем  создавать собственные классы Thread, наследуя их. После создания класса потока, затем мы можем создать 
объект потока и запустить его. Код показан ниже.

```Python
"""
Python 3.9 используем многопоточность где поток как объект класса
Название файла '04.16. многопоточная_загрузка.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

import threading  # подключаем модуль многопоточной работы
from random import randint  # подключаем функцию генерации целых чисел
from time import time, sleep  # подключаем модуль работы со временем

class DownloadTask(threading.Thread):  # создаем класс

    def __init__(self, filename):  # инициализация класса
        super().__init__()
        self._filename = filename

    def run(self):  # метод выполнения
        print('Начать загрузку %s...' % self._filename)  # перед загрузкой выводим сообщение на экран
        time_to_download = randint(5, 10)  # генерация случайного числа от 5 до 10    
        print('Оставшееся время %d секунд.' % time_to_download)  # выводим сообщение с отображением ост. времени
        sleep(time_to_download)  # ждем это случайное время
        print('%s загрузка завершена!' % self._filename)  # выводим сообщение с отображением имени файла


def main():  # главная функция
    start = time()  # время начала выполнения программы
    # Поместите несколько задач загрузки в несколько потоков для выполнения
    # . После запуска потока он обратится к нему и выполнит
    # метод run.
    thread1 = DownloadTask('Python.pdf')  # Создаем объект потока через собственный класс потока
    thread1.start()  # начало выполнения потока  
    thread2 = DownloadTask('Peking.avi')  # Создаем объект потока через собственный класс потока
    thread2.start()  # начало выполнения потока
    thread1.join()  # ожидание выполнения
    thread2.join()  # ожидание выполнения
    end = time()  # время конца выполнения программы
    print('Всего потребовалось %.3f секунд..' % (end - start))  # сообщение о окончании с вычислением общего времени
    # загрузки


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию

# Обратите внимание, что потоки, созданные с помощью threading.Thread, по умолчанию не являются потоками демона

```

Поскольку несколько потоков могут совместно использовать пространство памяти процесса, относительно просто 
реализовать связь между несколькими потоками. Самый простой способ, который можно придумать, - это установить 
глобальную переменную, и несколько потоков могут совместно использовать эту глобальную переменную. Но когда 
несколько потоков совместно используют одну и ту же переменную (мы обычно называем ее «ресурсом»), это может 
привести к неконтролируемым результатам, что приведет к сбою программы или даже к сбою. Если ресурс конкурирует за 
использование несколькими потоками, то мы обычно называем его «критическим ресурсом», и доступ к «критическому 
ресурсу» должен быть защищен, иначе ресурс будет в «хаотическом» состоянии. В следующем примере демонстрируется 
сценарий, в котором 100 потоков переводят деньги на один и тот же банковский счет (переводят 1 рубль). В этом 
примере банковский счет является критическим ресурсом, и мы можем получить ошибки если нет защиты.

```Python
"""
Python 3.9 Несколько потоков обмениваются данными без блокировки
Название файла '05.многопоточная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

from time import sleep  # подключаем модуль работы со временем
from threading import Thread, Lock  # подключаем модуль многопоточной работы


class Account(object):  # создаем класс

    def __init__(self):  # инициализация класса
        self._balance = 0
        self._lock = Lock()

    def deposit(self, money):  # метод щет (на входе сумма денег)
        # Получить блокировку перед выполнением последующего кода
        self._lock.acquire()
        try:
            new_balance = self._balance + money
            sleep(0.01)
            self._balance = new_balance
        finally:
            # Этот код помещается наконец, чтобы гарантировать, что операция снятия блокировки должна быть выполнена
            self._lock.release()

    @property  # спец.метод (свойство) геттер или аксессор (устанавливает значение из вне класса)
    def balance(self):  # метод имени (т.е. при обращении к методу имени - вы получите значение этого атрибута)
        return self._balance  # возвращает значение атрибута имени


class AddMoneyThread(Thread):  # создаем класс

    def __init__(self, account, money):  # инициализация класса (на входе аргументы имя аккаунта и количество денег)
        super().__init__()
        self._account = account  # создаем атрибут равный аргументу аккаунта
        self._money = money  # создаем атрибут равный аргументу денег

    def run(self):  # метод выполнение перевода
        self._account.deposit(self._money)


def main():  # главная функция
    account = Account()  # создаем объект класса аккаунт
    threads = []  # создаем пустой список
    # Создаем 100 потоков депозита для внесения денег на тот же счет
    for _ in range(100):  # в диапазоне от 1 до 100
        t = AddMoneyThread(account, 1)  # создаем объект класса процесс добавить деньги (передаем имя акк, 1 рубль)
        threads.append(t)
        t.start()  # запускаем процесс
    # Дождитесь выполнения всех потоков депозита
    for t in threads:  # цикл перечисления всех потоков
        t.join()  # ожидает выполнение потока
    print('Щет пополнен, текущий баланс составляет: %d рублей' % account.balance)


if __name__ == '__main__':  # проверка основной программы
    main()  # запуск главной функции

```

При запуске вышеуказанной программы результат удивителен: каждый из 100 потоков переводит 1 рубль на счет, результат 
на самом деле намного меньше 100 рублей. Это происходит потому, что мы не защитили «критический ресурс» банковских 
счетов. Когда несколько потоков вносят деньги на счет одновременно, new_balance = self._balance + money эта строка 
кода будет выполняться одновременно, и все балансы счетов, полученные несколькими потоками, не изменятся, поэтому 
операция +1 рубль в отдельных потоках не была выполнена, и поэтому был получен неправильный результат. В этом случае 
метод многопоточности блокировки «Lock» может пригодиться. Мы можем защитить «критические ресурсы» с помощью 
«блокировок». Только потоки, получившие «блокировку», могут получить доступ к «критическим ресурсам», а другие 
потоки, которые не получили «блокировку», могут быть заблокированы только до тех пор, пока поток, имеющий 
полученная «блокировка» не будет снят. Следующий код демонстрирует, как использовать «блокировку» для защиты 
операции банковского счета, чтобы получить правильный результат.

```Python
"""
Python 3.9 Несколько потоков обмениваются данными с блокировкой
Название файла '06.многопоточная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

import time  # подключаем модуль работы со временем
import threading  # подключаем модуль многопоточной работы


class Account(object):  # создаем класс

    def __init__(self):  # инициализация класса
        self._balance = 0
        self._lock = threading.Lock()

    def deposit(self, money):  # метод депозит (на входе сумма денег)
        # Код может продолжить выполнение после получения блокировки
        self._lock.acquire()
        try:
            new_balance = self._balance + money
            time.sleep(0.01)
            self._balance = new_balance
        finally:
            # После завершения операции не забудьте снять блокировку
            self._lock.release()

    @property  # спец.метод (свойство) геттер или аксессор (устанавливает значение из вне класса)
    def balance(self):  # метод имени (т.е. при обращении к методу имени - вы получите значение этого атрибута)
        return self._balance  # возвращает значение атрибута имени


if __name__ == '__main__':  # проверка основной программы
    account = Account()
    # Создайте 100 потоков депозита для внесения денег на тот же счет
    for _ in range(100):
        threading.Thread(target=account.deposit, args=(1,)).start()
    # Дождитесь выполнения всех потоков депозита
    time.sleep(2)
    print('Щет пополнен, текущий баланс составляет: %d рублей' % account.balance)
```

Еще более прискорбно то, что многопоточность Python не использует преимущества многоядерных характеристик ЦП. Это 
можно подтвердить, запустив несколько потоков, выполняющих бесконечный цикл. Причина этого в том, что интерпретатор 
Python имеет «глобальную блокировку интерпретатора» (GIL). Перед выполнением любого потока необходимо получить 
блокировку GIL, а затем каждый раз, когда выполняется 100 байт кода, интерпретатор автоматически освобождает GIL. 
lock., позволяя другим потокам иметь возможность выполняться, это историческая проблема, но даже в этом случае, 
как мы приводили пример ранее, использование многопоточности по-прежнему положительно с точки зрения повышения 
эффективности выполнения и улучшения взаимодействия с пользователем.

### Многопроцессорность или многопоточность

Независимо от того, является ли это многопроцессорным или многопоточным, если их количество велико, эффективность 
определенно не улучшится. Почему? Давайте проведем аналогию. Предположим, вы, к сожалению, готовитесь к 
вступительным экзаменам в старшую школу. Каждую ночь вам нужно выполнять 5 домашних заданий по русскому, 
математике, английскому языку, физике и химии. Каждое домашнее задание занимает 1 час. Если вы сначала потратите 1 
час на выполнение домашнего задания по русскому языку, после его выполнения потратите 1 час на домашнее задание по 
математике, чтобы вы выполнили все их одно за другим, а в целом это займет 5 часов. Этот метод называется 
однозадачным. Если вы планируете переключиться на модель многозадачности, вы можете 1 минуту изучить китайский язык,
затем переключиться на домашнее задание по математике, выполнить 1 минуту, затем переключиться на английский и т. д.
Если скорость переключения достаточно высока, этот метод будет выполнять с одноядерным процессором. Многозадачность 
такая же. С точки зрения наблюдателя, вы пишете 5 домашних заданий одновременно.

Однако за переключение домашнего задания приходится платить. Например, чтобы переключиться с русского на 
математику, вы должны сначала запомнить что уже выполнили и очистить стол (это называется сохранением сцены), затем 
прежде чем вы начнете делать домашнее задание по математике Вам необходимо открыть учебник и найти 
циркуль и линейку (это называется подготовкой к новой среде). Операционная система одинакова при переключении 
процессов или потоков. Она должна сохранить текущую среду выполнения (состояние регистров ЦП, страницу памяти и т. 
д.), А затем подготовить среду выполнения новой задачи (восстановить последнее состояние регистра, переключить 
страницы памяти и т. д.) до начала выполнения. Хотя этот процесс переключения происходит быстро, он также требует 
времени. Если одновременно выполняются тысячи задач, операционная система может быть в основном занята 
переключением задач, и на выполнение задач совсем не так много времени. Наиболее распространенная ситуация - 
жужжание жесткого диска, отсутствие окна ответить, и система находится в состоянии приостановки анимации. Рессурс 
Вашего компьютера исчерпан, он не безграничен, Ваш компьютер начинает тормозить, лагать или даже зависнуть. 
Следовательно, как только многозадачность достигает предела, это приведет к резкому падению производительности 
системы и, в конечном итоге, к сбою всех задач.

Второе соображение относительно того, следует ли использовать многозадачность  - это тип задачи, который можно 
разделить на вычислительно-интенсивные и с интенсивным вводом-выводом. Характерной чертой задач с интенсивными 
вычислениями является выполнение большого количества вычислений и использование ресурсов ЦП, таких как кодирование 
и декодирование видео или преобразование формата и т. д. Эта задача зависит от вычислительной мощности ЦП. Хотя она 
также может быть выполнена с помощью многозадачности. Чем больше задача - тем больше времени затрачивается 
на переключение задач, тем ниже эффективность ЦП для выполнения задач. Вычислительные задачи в основном потребляют 
ресурсы ЦП. Эффективность выполнения таких задач с помощью языков сценариев, таких как Python, обычно очень низкая. 
Язык C является наиболее подходящим для таких задач. Ранее мы упоминали, что Python имеет встроенный код C / C ++.

### Механизмы.

Помимо задач, требующих большого объема вычислений, другие задачи, связанные с вводом-выводом сети и носителей, 
могут рассматриваться как задачи с интенсивным вводом-выводом. Этот тип задач характеризуется низким потреблением 
ресурсов ЦП, и большая часть времени ожидания операции ввода-вывода уже завершена (потому что скорость 
ввода-вывода намного ниже скорости процессора и памяти). Для задач с интенсивным вводом-выводом, если вы начнете 
многозадачность, вы можете уменьшить время ожидания ввода-вывода и позволить ЦП работать эффективно. Существует 
большой класс задач, связанных с интенсивным вводом-выводом, включая сетевые приложения и веб-приложения, в которых 
мы скоро будем участвовать.

### Однопоточный асинхронный ввод / вывод

Самым важным в улучшении операций ввода-вывода в современных операционных системах является поддержка асинхронного 
ввода-вывода. Если вы в полной мере используете поддержку асинхронного ввода-вывода, предоставляемую операционной 
системой, вы можете использовать однопроцессную однопоточную модель для выполнения многозадачности. Эта новая модель 
называется моделью, управляемой событиями. Nginx - это веб-сервер, поддерживающий асинхронный ввод-вывод. Он 
использует однопроцессную модель на одноядерном ЦП для эффективной поддержки многозадачности. На многоядерном ЦП вы 
можете запускать несколько процессов (число совпадает с числом ядер ЦП), полностью используя многоядерный ЦП. 
Серверные программы, разработанные с помощью Node.js, также используют этот рабочий режим, который также является 
популярным решением для параллельного программирования.

На языке Python модель программирования с одним потоком и асинхронным вводом-выводом называется сопрограммой. 
Благодаря поддержке сопрограммы можно писать эффективные многозадачные программы, основанные на событиях. Самым 
большим преимуществом сопрограмм является чрезвычайно высокая эффективность выполнения, поскольку переключение 
подпрограмм - это не переключение потоков, а управляется самой программой, поэтому нет накладных расходов на 
переключение потоков. Второе преимущество сопрограммы заключается в том, что она не требует многопоточного 
механизма блокировки, потому что существует только один поток и нет конфликта записи переменных одновременно. В 
сопрограмме общие ресурсы не нуждаются в блокировке, и для оценки требуется только состояние выполнения. 
Эффективность намного выше, чем многопоточность. Если вы хотите в полной мере использовать многоядерность ЦП, самый 
простой способ - это многопроцессорность + асихронность, которая не только полностью использует многоядерность, но и 
дает полную возможность продемонстрировать высокую эффективность сопрограммы для получения чрезвычайно высокой 
производительности.

### Приложения

#### Поместите трудоемкие задачи в потоки, чтобы улучшить взаимодействие с пользователем.

В интерфейсе, показанном ниже, есть две кнопки: «Загрузить» и «О программе». Загрузка файлов в Интернете займет 10 
секунд, сама кнопка «Загрузить» станет не доступна для нажатия. Если вы не используете «многопоточность». , мы будем. 
Было обнаружено, что при нажатии кнопки «Загрузить» другие части всей программы блокируются этой трудоемкой задачей 
и не могут быть выполнены. Это, очевидно, очень неприятно для пользователя. Код показан ниже.

```Python
"""
Python 3.9 При использовании одного потока запускаем GUI приложение.
Название файла '07.однопоточная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

import time  # модуль работы со временем
import tkinter  # модуль работы с GUI-приложения
import tkinter.messagebox  # модуль работы с сообщениями GUI


def download():  # функция имитации загрузки в 10 секунд при нажатии на кнопку загрузить
    time.sleep(10)  # время ожидания 10 секунд
    tkinter.messagebox.showinfo('подсказка', 'загрузка завершена!')  # выводим сообщение в отдельное окно


def show_about():  # функция вывести сообщение при нажатии на кнопку О программе
    tkinter.messagebox.showinfo('О программе', 'Автор: Андрей (v1.0)')


def main():  # главная функция
    top = tkinter.Tk()  # создаем объект графического приложения
    top.title('Программа загрузки')  # название окна GUI
    top.geometry('200x150')  # размер окна GUI
    top.wm_attributes('-topmost', True)  # положение окна

    panel = tkinter.Frame(top)  # создаем панель с кнопками
    button1 = tkinter.Button(panel, text='Загрузить', command=download)  # прописываем кнопку
    button1.pack(side='left')  # размещаем ее на панели
    button2 = tkinter.Button(panel, text='О программе', command=show_about)  # прописываем кнопку
    button2.pack(side='right')  # размещаем ее на панели
    panel.pack(side='bottom')  # обрабатываем нашу панель кнопок

    tkinter.mainloop()  # обработчик нашего окна


if __name__ == '__main__':  # если запущена это программа как главная
    main()  # запускаем главную функцию


# После того, как вы нажмете кнопку загрузки без использования многопоточности, эта операция займет 10 секунд
# Весь основной цикл сообщений также будет заблокирован на 10 секунд и не сможет реагировать на другие события
# На самом деле последовательное выполнение подзадач без причинно-следственной связи нецелесообразно
```

Если вы используете многопоточность для помещения трудоемких задач в отдельный поток для выполнения, чтобы основной 
поток не был заблокирован трудоемкими задачами, то измененный код показан ниже.

```Python
"""
Python 3.9 При использовании нескольких потоков трудоемкие задачи выполняются в отдельных потоках.
Название файла '08.многопоточная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""
import time  # подключаем модуль времени
import tkinter  # модуль работы с GUI
import tkinter.messagebox  # модуль работы с GUI сообщениями
from threading import Thread  # подключаем модуль многопоточной работы


def main():  # главная функция

    class DownloadTaskHandler(Thread):

        def run(self):
            # Имитация задачи загрузки занимает 10 секунд
            time.sleep(10)
            tkinter.messagebox.showinfo('подсказка', 'загрузка завершена!')
            # Включить кнопку загрузки
            button1.config(state=tkinter.NORMAL)

    def download():  # функция загрузки (в процессе загрузки ещер раз на кнопку загрузить нельзя)
        # Отключить кнопку загрузки
        button1.config(state=tkinter.DISABLED)
        # Установите поток как поток демона через параметр демона (основная программа больше не будет продолжать выполнение при выходе)
        DownloadTaskHandler(daemon=True).start()

    def show_about():  # функция кнопки о программе
        tkinter.messagebox.showinfo('О программе', 'Автор: Андрей (v1.0)')

    top = tkinter.Tk()
    top.title('Загрузка информации')
    top.geometry('200x150')
    top.wm_attributes('-topmost', 1)

    panel = tkinter.Frame(top)
    button1 = tkinter.Button(panel, text='Загрузить', command=download)
    button1.pack(side='left')
    button2 = tkinter.Button(panel, text='О программе', command=show_about)
    button2.pack(side='right')
    panel.pack(side='bottom')

    tkinter.mainloop()


if __name__ == '__main__':  # проверка основной программы
    main()  # запуск главной функции
```

####  Используйте несколько процессов, чтобы «разделять и побеждать» сложные задачи.

Давайте выполним трудоемкую задачу по суммированию 1 ~ 100000000. Эта задача очень проста и может быть решена с 
небольшим знанием циклов. Код показан ниже.


```Python
"""
Python 3.9 Вычисление последовательно в один поток.
Название файла '09.однопоточная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

from time import time  # подключаем модуль времени


def main():  # главная функция
    total = 0  # создаем переменную равную 0
    number_list = [x for x in range(1, 100000001)]  # создаем список с значенями от 1 до 100 000 000 
    start = time()  # засекаем время начала запуска программы
    for number in number_list:  # перебираем все элементы списки
        total += number  # добовляем к переменной каждый элемент списка
    print(total)  # выводим результат суммирования на экран
    end = time()  # засекаем время конца программы
    print('Execution time: %.3fs' % (end - start))  # выводим время на суммирование на экран


if __name__ == '__main__':  # проверка основной программы
    main()  # запуск главной функции
```

В приведенном выше коде я намеренно создал контейнер списка и заполнил 100 000 000 чисел. Этот шаг на самом деле 
занимает много времени, поэтому ради справедливости, мы разобъем эту задачу на 8 процессов. При этом мы не 
рассматриваем время, затраченное на операцию нарезки списка в данный момент, но учитывается только время операции и 
комбинированный результат операции. Код выглядит следующим образом.

```Python
"""
Python 3.9 Вычисление последовательно в 8 процессов.
Название файла '18.многопроцессорная_работа.py'

Version: 0.1
Author: Andrej Marinchenko
Date: 2021-11-13
"""

from multiprocessing import Process, Queue
from time import time


def task_handler(curr_list, result_queue):
    total = 0
    for number in curr_list:
        total += number
    result_queue.put(total)


def main():  # главная функция
    processes = []
    number_list = [x for x in range(1, 100000001)]
    result_queue = Queue()
    index = 0
    # разбиваем задачу на 8 процессов
    for _ in range(8):
        p = Process(target=task_handler,
                    args=(number_list[index:index + 12500000], result_queue))
        index += 12500000
        processes.append(p)
        p.start()
    start = time()  # время начала выполнения программы
    for p in processes:
        p.join()  # ожидаем окончание каждого процесса
    
    total = 0
    while not result_queue.empty():
        total += result_queue.get()
    print(total)
    end = time()
    print('Execution time: ', (end - start), 's', sep='')


if __name__ == '__main__':  # проверка основной программы
    main()  # запуск главной функции
```

Сравните результаты выполнения двух фрагментов кода (на MacBook, который я использую в настоящее время, приведенный 
выше код занимает около 6 секунд, тогда как следующий код занимает менее 1 секунды. Опять же, мы просто сравнили 
время расчета, не учитывая время, затрачиваемое на создание списка и операции нарезки) .После использования 
нескольких процессов достигается большее время выполнения ЦП и лучшее использование многоядерных характеристик ЦП, 
что значительно сокращает время выполнения программы и тем больше объем вычислений большой эффект более очевиден. 
Конечно, при желании вы можете развернуть несколько процессов на разных компьютерах для создания распределенного 
процесса. Конкретный метод заключается в том, чтобы предоставить общий доступ к объекту через сеть через 
multiprocessing. managers диспетчер, предоставленный в модуле Queue (зарегистрируйтесь в сети, чтобы другие компьютеры 
имели доступ), эта часть контента также остается на усмотрение поисковых роботов.

[Вернуться на главную](https://github.com/BEPb/Python-100-days)

[К следующему занятию](https://github.com/BEPb/Python-100-days/blob/master/%D0%94%D0%B5%D0%BD%D1%8C%2001-15/%D0%94%D0%B5%D0%BD%D1%8C%2014/README.md)
