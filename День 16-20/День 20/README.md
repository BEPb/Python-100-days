- Параллельное и асинхронное программирование - многопоточный / многопроцессорный / асинхронный ввод-вывод / 
  асинхронный и ожидающий


### Параллельное и асинхронное программирование (день 20)


### Параллельное программирование

Существует три сценария параллельного программирования в Python: многопоточный, многопроцессный и асинхронный 
ввод-вывод. Преимущество параллельного программирования заключается в повышении эффективности выполнения программ и 
улучшении взаимодействия с пользователем;

В Python есть несколько способов параллельного программирования:

1. Модуль threading - позволяет создавать потоки выполнения и распределять задачи между ними. Однако из-за 
   особенностей реализации интерпретатора Python, потоки в этом модуле не являются идеально параллельными и могут 
   иметь ограничения в производительности.  

2. Модуль multiprocessing - позволяет создавать процессы выполнения, каждый из которых работает независимо от других.
   Каждый процесс имеет свою собственную память и выполняет свои задачи параллельно с другими процессами. Однако 
   из-за особенностей работы с процессами, передача данных между ними может быть затруднительной и требует 
   использования специальных техник.   

3. Модуль asyncio - позволяет использовать асинхронный подход к программированию, при котором задачи выполняются в 
   одном потоке, но процессор переключается между задачами в зависимости от их состояния. Этот подход может быть 
   полезен в задачах, связанных с сетевым вводом-выводом или с другими блокирующими операциями.  
 
Каждый из этих способов имеет свои достоинства и недостатки и может быть выбран в зависимости от конкретной задачи и 
условий ее выполнения. 

Пример:
```python
import glob
import os
import time

from threading import Thread
from PIL import Image


class ThumbnailThread(Thread):

    def __init__(self, infile):
        self.infile = infile
        super().__init__()

    def run(self):
        file, ext = os.path.splitext(self.infile)
        filename = file[file.rfind('/') + 1:]
        for size in (32, 64, 128):
            outfile = f'{filename}_{size}_{size}.png'
            image = Image.open(self.infile)
            image.thumbnail((size, size))
            image.save(outfile, format='PNG')


def main():
    start = time.time()
    threads = []
    for infile in glob.glob('images/*'):
        t = ThumbnailThread(infile)
        t.start()
        threads.append(t)
    for t in threads:
        t.join()
    end = time.time()
    print(f'Время затраченное на выполнение: {end - start} секунд')



if __name__ == '__main__':
    main()
```

Эта программа создает миниатюры заданных изображений различных размеров. Она использует библиотеку PIL для обработки 
изображений и многопоточность для повышения производительности. 

Основная функция `main()` начинается с измерения времени начала выполнения (в переменную `start`), продолжается с 
инициализации списка потоков (`threads`) и последующим запуском новых потоков для каждого изображения в папке 
`images`. Каждый поток создается как экземпляр класса `ThumbnailThread`, который принимает путь к файлу изображения 
в качестве аргумента конструктора.   

Когда каждый поток запущен, он вызывает метод `run()`, который извлекает имя файла и его расширение, затем создает и 
сохраняет экземпляры миниатюр для каждого заданного размера. Их размер задается в цикле, который перебирает значения 
32, 64 и 128. Каждый раз, когда размер изменяется, создается новый файл с соответствующими размерами в его названии.  

После того, как все потоки завершили свою работу, функция `main()` измеряет время завершения выполнения (в 
переменную `end`) и выводит разницу между временем начала и конца выполнения программы в секундах. 

Эта программа позволяет обрабатывать несколько изображений одновременно, что делает процесс создания миниатюр 
гораздо более быстро и эффективным относительно последовательного преобразования. 

Еще пример, решающий точно такую же задачу, но через использование объекта пула потоков:
```python
import glob
import os
import time

from concurrent.futures import ThreadPoolExecutor
from PIL import Image


def gen_thumbnail(infile):
    file, ext = os.path.splitext(infile)
    filename = file[file.rfind('/') + 1:]
    for size in (32, 64, 128):
        outfile = f'{filename}_{size}_{size}.png'
        image = Image.open(infile)
        image.thumbnail((size, size))
        image.save(outfile, format='PNG')


def main():
    pool = ThreadPoolExecutor(max_workers=30)
    futures = []
    start = time.time()
    for infile in glob.glob('images/*'):
        # метод отправки - это неблокирующий метод
        # Даже если количество рабочих потоков было израсходовано, метод submit примет отправленную задачу
        future = pool.submit(gen_thumbnail, infile)
        futures.append(future)
    for future in futures:
        # Метод результата - это метод блокировки, если поток еще не завершен
        # Временно невозможно получить результат выполнения потока, код здесь будет заблокирован
        future.result()
    end = time.time()
    print(f'Время затраченное на выполнение: {end - start} секунд')
    # выключение также является неблокирующим методом, если отправленная задача была не завершена
    # Пул потоков - это завершение работы, которое не перестанет работать, и отправка задачи не будет выполнена и вызовет исключение
    pool.shutdown()


if __name__ == '__main__':
    main()

```
Данная программа создает уменьшенные копии изображений из папки "images" и сохраняет их в той же папке с добавлением 
размера в конце имени файла. Для этого используется модуль Pillow (PIL). 

Основная функция - gen_thumbnail(infile) - принимает путь к исходному файлу изображения и создает уменьшенные копии 
размером 32, 64 и 128 пикселей. Она используется в параллельном режиме благодаря использованию пула потоков 
(ThreadPoolExecutor) и методов submit() и result().  

Основная функция main() создает пул потоков (ThreadPoolExecutor) и запускает выполнение функции gen_thumbnail() на 
каждом файле изображения в папке "images". Для каждого отправленного задания сохраняется объект Future в списке 
futures.  

Затем программа ожидает завершения всех заданий, получая результаты выполнения через метод result() для каждого 
объекта Future в списке futures. 

После выполнения всех заданий программа завершается и выводит общее время выполнения.

Важно отметить, что методы submit() и result() являются неблокирующими. Это значит, что отправление задания в пул 
потоков происходит мгновенно, даже если все рабочие потоки уже заняты выполнением других заданий. Однако метод result
() блокирует выполнение, пока результат выполнения задания не будет получен. Таким образом, программа не будет 
завершена, пока все задания не будут выполнены.   



Масштабируемая производительность системы
-Вертикальное расширение-Увеличение производительности обработки одного узла
-Горизонтальное расширение-превращение одного узла в несколько узлов (разделение чтения-записи / распределенный кластер)
Параллельное программирование - ускорение выполнения программы / улучшение взаимодействия с пользователем
Трудоемкие задачи выполняются максимально независимо, не блокируют другие части кода.
- Многопоточность
1. Создайте объект Thread, чтобы указать атрибуты target и args, и запустите поток с помощью метода start.
2. Наследуйте класс Thread и переопределите метод run, чтобы определить задачи, выполняемые потоком.
3. Создайте объект пула потоков ThreadPoolExecutor и отправьте задачу для выполнения через submit.
Третий способ может получить результат выполнения потока в будущем через метод result объекта Future
Вы также можете использовать метод done, чтобы определить, закончился ли поток
- мульти-прогресс
-Асинхронный ввод / вывод

Межпоточная связь (обмен данными) очень проста, потому что память одного и того же процесса может совместно использоваться
Межпроцессное взаимодействие (общие данные) проблематично, потому что операционная система будет защищать память, выделенную для процесса.
Чтобы добиться многопроцессорной связи, вы обычно можете использовать системные каналы, сокеты и трехсторонние службы.
multiprocessing.Queue
Поток демона
Демон-firewalld / httpd / mysqld
Процессы, которые не сохраняются, когда система не работает, не препятствуют остановке системы, потому что процесс еще не завершил выполнение.


Ситуация, когда несколько потоков конкурируют за ресурсы.

  ```Python
  """
  多线程程序如果没有竞争资源处理起来通常也比较简单
  当多个线程竞争临界资源的时候如果缺乏必要的保护措施就会导致数据错乱
  说明：临界资源就是被多个线程竞争的资源
  """
  import time
  import threading
  
  from concurrent.futures import ThreadPoolExecutor
  
  
  class Account(object):
      """银行账户"""
  
      def __init__(self):
          self.balance = 0.0
          self.lock = threading.Lock()
  
      def deposit(self, money):
          # 通过锁保护临界资源
          with self.lock:
              new_balance = self.balance + money
              time.sleep(0.001)
              self.balance = new_balance
  
  
  def main():
      """主函数"""
      account = Account()
      # 创建线程池
      pool = ThreadPoolExecutor(max_workers=10)
      futures = []
      for _ in range(100):
          future = pool.submit(account.deposit, 1)
          futures.append(future)
      # 关闭线程池
      pool.shutdown()
      for future in futures:
          future.result()
      print(account.balance)
  
  
  if __name__ == '__main__':
      main()
  ```
  
  измените приведенную выше программу, запустите 5 потоков, чтобы сэкономить деньги на счете, 5 потоков, чтобы снять деньги со счета, и приостановить поток, если баланс недостаточен. для достижения вышеуказанных целей необходимо планировать потоки, которые экономят деньги и снимают деньги, потоки, которые снимают деньги, когда баланс недостаточен, приостанавливаются и освобождаются блокировки, в то время как потоки, которые экономят деньги, вводят деньги и уведомляют потоки, которые снимают деньги, чтобы они проснулись от приостановления. модуль можно использовать для реализации планирования потоков, объект также создается на основе блокировок, код выглядит следующим образом:threadingCondition
  ```Python
  """
  多个线程竞争一个资源 - 保护临界资源 - 锁（Lock/RLock）
  多个线程竞争多个资源（线程数>资源数） - 信号量（Semaphore）
  多个线程的调度 - 暂停线程执行/唤醒等待中的线程 - Condition
  """
  from concurrent.futures import ThreadPoolExecutor
  from random import randint
  from time import sleep
  
  import threading
  
  
  class Account:
      """银行账户"""
  
      def __init__(self, balance=0):
          self.balance = balance
          lock = threading.RLock()
          self.condition = threading.Condition(lock)
  
      def withdraw(self, money):
          """取钱"""
          with self.condition:
              while money > self.balance:
                  self.condition.wait()
              new_balance = self.balance - money
              sleep(0.001)
              self.balance = new_balance
  
      def deposit(self, money):
          """存钱"""
          with self.condition:
              new_balance = self.balance + money
              sleep(0.001)
              self.balance = new_balance
              self.condition.notify_all()
  
  
  def add_money(account):
      while True:
          money = randint(5, 10)
          account.deposit(money)
          print(threading.current_thread().name, 
                ':', money, '====>', account.balance)
          sleep(0.5)
  
  
  def sub_money(account):
      while True:
          money = randint(10, 30)
          account.withdraw(money)
          print(threading.current_thread().name, 
                ':', money, '<====', account.balance)
          sleep(1)
  
  
  def main():
      account = Account()
      with ThreadPoolExecutor(max_workers=15) as pool:
          for _ in range(5):
              pool.submit(add_money, account)
          for _ in range(10):
              pool.submit(sub_money, account)
  
  
  if __name__ == '__main__':
      main()
  ```
  
- МНОГОПРОЦЕССНЫЙ: МНОГОПРОЦЕССНЫЙ МОЖЕТ ЭФФЕКТИВНО РЕШИТЬ ПРОБЛЕМУ GIL, РЕАЛИЗАЦИЯ МНОГОПРОЦЕССНОГО ОСНОВНОГО КЛАССА ЗАКЛЮЧАЕТСЯ В ТОМ, ЧТО ДРУГИЕ ВСПОМОГАТЕЛЬНЫЕ КЛАССЫ АНАЛОГИЧНЫ ТЕМ, КОТОРЫЕ НАХОДЯТСЯ В МОДУЛЕ, ОБМЕН ДАННЫМИ МЕЖДУ ПРОЦЕССАМИ МОЖЕТ ИСПОЛЬЗОВАТЬ КОНВЕЙЕР, СОКЕТ И Т.Д., В МОДУЛЕ ЕСТЬ КЛАСС, КОТОРЫЙ ПРЕДОСТАВЛЯЕТ НЕСКОЛЬКО ОЧЕРЕДЕЙ СОВМЕСТНОГО ИСПОЛЬЗОВАНИЯ ПРОЦЕССОВ НА ОСНОВЕ КОНВЕЙЕРА И МЕХАНИЗМА БЛОКИРОВКИ. НИЖЕ ПРИВЕДЕН ПРИМЕР МНОГОПРОЦЕССНОГО И ПУЛА ПРОЦЕССОВ В ОФИЦИАЛЬНОМ ДОКУМЕНТЕ.ProcessthreadingmultiprocessingQueue
  ```Python
  """
  多进程和进程池的使用
  多线程因为GIL的存在不能够发挥CPU的多核特性
  对于计算密集型任务应该考虑使用多进程
  time python3 example22.py
  real    0m11.512s
  user    0m39.319s
  sys     0m0.169s
  使用多进程后实际执行时间为11.512秒，而用户时间39.319秒约为实际执行时间的4倍
  这就证明我们的程序通过多进程使用了CPU的多核特性，而且这台计算机配置了4核的CPU
  """
  import concurrent.futures
  import math
  
  PRIMES = [
      1116281,
      1297337,
      104395303,
      472882027,
      533000389,
      817504243,
      982451653,
      112272535095293,
      112582705942171,
      112272535095293,
      115280095190773,
      115797848077099,
      1099726899285419
  ] * 5
  
  
  def is_prime(n):
      """判断素数"""
      if n % 2 == 0:
          return False
  
      sqrt_n = int(math.floor(math.sqrt(n)))
      for i in range(3, sqrt_n + 1, 2):
          if n % i == 0:
              return False
      return True
  
  
  def main():
      """主函数"""
      with concurrent.futures.ProcessPoolExecutor() as executor:
          for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
              print('%d is prime: %s' % (number, prime))
  
  
  if __name__ == '__main__':
      main()
  ```

  > ключевые моменты: многопоточное и многопроцессное сравнение.
  >
  > несколько потоков необходимы в следующих случаях:

    Программы должны поддерживать многие общие состояния( особенно переменные), а списки, словари и коллекции в Python являются потокобезопасными, поэтому обслуживание общего состояния с помощью потоков, а не процессов, обходится относительно не по цене.
    ПРОГРАММА ТРАТИТ МНОГО ВРЕМЕНИ НА ОПЕРАЦИИ ВВОДА-ВЫВОДА, НЕ ТРЕБУЕТ МНОГО ПАРАЛЛЕЛЬНЫХ ВЫЧИСЛЕНИЙ И НЕ ТРЕБУЕТ МНОГО ПАМЯТИ.

несколько процессов необходимы в следующих случаях:

    программа выполняет задачи с интенсивным использованием вычислений (например, операции байт-кода, обработка данных, научные вычисления).
    входные данные программы могут быть разделены параллельно на блоки, а результаты операции могут быть объединены.
    ПРОГРАММА НЕ ИМЕЕТ КАКИХ-ЛИБО ОГРАНИЧЕНИЙ НА ИСПОЛЬЗОВАНИЕ ПАМЯТИ И НЕ СИЛЬНО ЗАВИСИТ ОТ ОПЕРАЦИЙ ВВОДА-ВЫВОДА (НАПРИМЕР, ЧТЕНИЕ И ЗАПИСЬ ФАЙЛОВ, СОКЕТОВ И Т.Д.).


- Асинхронная обработка: Выбор задач из очереди задач планировщика, выполняющей эти задачи в перекрестном режиме, не гарантирует, что задачи будут выполняться в определенном порядке, поскольку порядок выполнения зависит от готовности одной задачи в очереди уступить время обработки ЦП другой задаче. Асинхронные задачи обычно выполняются с помощью многозадачной совместной работы, и из-за неопределенности в отношении времени и последовательности выполнения необходимо получить результаты выполнения задачи с помощью обратного программирования или объектов. Python 3 поддерживает асинхронную обработку с помощью модулей и ключевых слов, которые официально перечислены в Python 3.7.futureasyncioawaitasync
  ```Python
  """
  异步I/O - async / await
  """
  import asyncio
  
  
  def num_generator(m, n):
      """指定范围的数字生成器"""
      yield from range(m, n + 1)
  
  
  async def prime_filter(m, n):
      """素数过滤器"""
      primes = []
      for i in num_generator(m, n):
          flag = True
          for j in range(2, int(i ** 0.5 + 1)):
              if i % j == 0:
                  flag = False
                  break
          if flag:
              print('Prime =>', i)
              primes.append(i)
  
          await asyncio.sleep(0.001)
      return tuple(primes)
  
  
  async def square_mapper(m, n):
      """平方映射器"""
      squares = []
      for i in num_generator(m, n):
          print('Square =>', i * i)
          squares.append(i * i)
  
          await asyncio.sleep(0.001)
      return squares
  
  
  def main():
      """主函数"""
      loop = asyncio.get_event_loop()
      future = asyncio.gather(prime_filter(2, 100), square_mapper(1, 100))
      future.add_done_callback(lambda x: print(x.result()))
      loop.run_until_complete(future)
      loop.close()
  
  
  if __name__ == '__main__':
      main()
  ```

  > 

    описание: приведенный выше код использует функцию для получения цикла событий системы по умолчанию, функция может получить объект, объект может добавить функцию обратного вызова при выполнении, метод объекта может ждать результатов совместного выполнения через объект.get_event_loopgatherfuturefutureadd_done_callbacklooprun_until_completefuture

  Python имеет трехстороннюю библиотеку с именем, которая предоставляет асинхронные HTTP-клиенты и серверы, которые могут работать с модулями и обеспечивают поддержку объектов. Функции, определяющие асинхронное выполнение и созданные асинхронные контексты, были введены и определены в Python 3.6, и они официально стали ключевыми словами в Python 3.7. Следующий код асинхронно извлекает страницу из 5 URL-адресов и извлекает заголовок сайта через именованную группу захвата регулярного выражения.aiohttpasyncioFutureasyncawait
  ```Python
  import asyncio
  import re
  
  import aiohttp
  
  PATTERN = re.compile(r'\<title\>(?P<title>.*)\<\/title\>')
  
  
  async def fetch_page(session, url):
      async with session.get(url, ssl=False) as resp:
          return await resp.text()
  
  
  async def show_title(url):
      async with aiohttp.ClientSession() as session:
          html = await fetch_page(session, url)
          print(PATTERN.search(html).group('title'))
  
  
  def main():
      urls = ('https://www.python.org/',
              'https://git-scm.com/',
              'https://www.jd.com/',
              'https://www.taobao.com/',
              'https://www.douban.com/')
      loop = asyncio.get_event_loop()
      cos = [show_title(url) for url in urls]
      loop.run_until_complete(asyncio.wait(cos))
      loop.close()
  
  
  if __name__ == '__main__':
      main()
  ```

  > В центре внимания: сравнение асинхронного ввода-вывода с несколькими процессами.
  >
  > Это хороший выбор, когда программа не требует истинной параллели или параллели, но в большей степени зависит от асинхронной обработки и обратных вызовов. Если в программе много ожидания и спящего режима, следует также учитывать, что она идеально подходит для написания серверов веб-приложений, которые не имеют требований к обработке данных в режиме реального времени.asyncioasyncio
  > 
  PPython также имеет много трехсторонних библиотек для параллельных задач, таких как: и т.д. В реальной разработке для повышения масштабируемости и параллели системы обычно существует как вертикальное масштабирование (увеличение вычислительной мощности одного узла), так и горизонтальное масштабирование (преобразование одного узла в несколько узлов). Разъединение приложений может быть достигнуто с помощью очередей сообщений, эквивалентных расширенной версии многопоточной очереди синхронизации, приложений на разных компьютерах, эквивалентных потокам, и общей распределенной очереди сообщений, которая является Queue в исходной программе. Наиболее распространенной и стандартизированной реализацией очередей сообщений (промежуточного ПО для сообщений) является AMCP (Advanced Steet Referred), который происходит от финансовой отрасли и предоставляет такие функции, как очереди, маршрутизация, надежная передача, безопасность и многое другое, в том числе: ActiveMQ Apache, RabbitMQ и многое другое.joblibPyMP

Для асинхронизации задачи можно использовать трехстороннюю библиотеку с именем. — это распределенная очередь задач, 
написанная Python, которая работает с распределенными сообщениями и может выступать в качестве прокси-сервера 
сообщений для серверной части на основе RabbitMQ или Reds.CeleryCelery  


[Вернуться на главную](https://github.com/BEPb/Python-100-days)

[К следующему занятию](https://github.com/BEPb/Python-100-days/blob/master/%D0%94%D0%B5%D0%BD%D1%8C%2016-20/%D0%94%D0%B5%D0%BD%D1%8C%2020/README.md)
