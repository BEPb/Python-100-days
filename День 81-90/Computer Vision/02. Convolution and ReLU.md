### Convolution and ReLU

```python
import numpy as np
from itertools import product

def show_kernel(kernel, label=True, digits=None, text_size=28):
    # Format kernel
    kernel = np.array(kernel)
    if digits is not None:
        kernel = kernel.round(digits)

    # Plot kernel
    cmap = plt.get_cmap('Blues_r')
    plt.imshow(kernel, cmap=cmap)
    rows, cols = kernel.shape
    thresh = (kernel.max()+kernel.min())/2
    # Optionally, add value labels
    if label:
        for i, j in product(range(rows), range(cols)):
            val = kernel[i, j]
            color = cmap(0) if val > thresh else cmap(255)
            plt.text(j, i, val, 
                     color=color, size=text_size,
                     horizontalalignment='center', verticalalignment='center')
    plt.xticks([])
    plt.yticks([])
```
### Введение
На последнем уроке мы увидели, что сверточный классификатор состоит из двух частей: 
- сверточной основы (convolutional base)
- заголовка плотных слоев (head of dense layers). 

Мы узнали, что задача базы состоит в том, чтобы извлекать из изображения визуальные элементы, которые 
затем использует голова для классификации изображения.  

В течение следующих нескольких уроков мы узнаем о двух наиболее важных типах слоев, которые вы обычно найдете в 
основе классификатора сверточных изображений. Это сверточный слой с активацией ReLU и максимальный уровень 
объединения. В Уроке 5 вы узнаете, как создать свою собственную свертку, объединяя эти слои в блоки, которые 
выполняют извлечение признаков.   

### Этот урок посвящен сверточному слою с его функцией активации ReLU.

#### Извлечение функций (Feature Extraction)
Прежде чем мы углубимся в детали свертки, давайте обсудим назначение этих слоев в сети. Мы собираемся увидеть, как 
эти три операции (свертка, ReLU и максимальное объединение) используются для реализации процесса извлечения признаков.

Извлечение признаков, выполняемое базой, состоит из трех основных операций:

1. Фильтрация изображения по определенному признаку (свертка)
2. Обнаружить эту функцию в отфильтрованном изображении (ReLU)
3. Сжать изображение для улучшения функций (максимальное объединение)


Пример процесса извлечения признаков.
Три этапа извлечения признаков.
Обычно сеть выполняет несколько параллельных извлечений на одном изображении. В современных свертках нередко 
последний слой базы создает более 1000 уникальных визуальных функций. 

#### Фильтр со сверткой (Filter with Convolution)
Сверточный слой выполняет этап фильтрации. Вы можете определить сверточный слой в модели Keras примерно так:
```python
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Conv2D(filters=64, kernel_size=3), # activation is None
    # More layers follow
])
```
```commandline
User settings:

   KMP_AFFINITY=granularity=fine,verbose,compact,1,0
   KMP_BLOCKTIME=0
   KMP_SETTINGS=1
   KMP_WARNINGS=0

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=128
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=false
   KMP_ENABLE_TASK_THROTTLING=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=8M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=4
   KMP_TOPOLOGY_METHOD=all
   KMP_USE_YIELD=1
   KMP_VERSION=false
   KMP_WARNINGS=false
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=1
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED: deprecated; max-active-levels-var=1
   OMP_NUM_THREADS: value is not defined
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=8M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'

2021-11-09 00:11:35.698345: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with 
default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 
```
Мы можем понять эти параметры, посмотрев на их отношение к весам и активациям слоя. Давай сделаем это сейчас.

### Вес
Веса, которые свёрточная сеть изучает во время обучения, в основном содержатся в его сверточных слоях. Эти веса мы 
называем ядрами. Мы можем представить их в виде небольших массивов: 

#### Ядро 3x3.
Ядро работает путем сканирования изображения и получения взвешенной суммы значений пикселей. Таким образом, ядро 
будет действовать как поляризованная линза, подчеркивая или ослабляя определенные паттерны информации. 
 

Ядро действует как своего рода линза.
Ядра определяют, как сверточный слой подключается к следующему слою. Вышеприведенное ядро соединит каждый нейрон на 
выходе с девятью нейронами на входе. Устанавливая размеры ядер с помощью kernel_size, вы указываете свёртке, как 
формировать эти соединения. Чаще всего ядро будет иметь нечетные размеры - например, kernel_size = (3, 3) или (5, 
5) - так что один пиксель находится в центре, но это не является обязательным требованием.   

Ядра в сверточном слое определяют, какие типы функций он создает. Во время обучения свёртка пытается узнать, какие 
функции необходимы для решения проблемы классификации. Это означает поиск лучших значений для его ядер. 

### Активации
Активации в сети мы называем картами функций. Это то, что получается, когда мы применяем фильтр к изображению; они 
содержат визуальные особенности, извлеченные ядром. Вот несколько ядер с изображениями созданных ими карт функций. 

По шаблону чисел в ядре вы можете определить типы создаваемых им карт функций. Как правило, то, что подчеркивает 
свертка во входных данных, будет соответствовать форме положительных чисел в ядре. Левое и среднее ядра выше будут 
фильтровать горизонтальные формы.

С помощью параметра filter вы сообщаете сверточному слою, сколько карт объектов вы хотите создать в качестве 
выходных данных. 

### Обнаружение с помощью ReLU
После фильтрации карты функций проходят функцию активации. Функция выпрямителя имеет такой график:

График функции активации ReLU.
График работы выпрямителя выглядит как линия, отрицательная часть которой «выпрямлена» до 0.
Нейрон с присоединенным выпрямителем называется выпрямленным линейным блоком. По этой причине мы также можем назвать 
функцию выпрямителя активацией ReLU или даже функцией ReLU. 

Активацию ReLU можно определить на собственном уровне активации, но чаще всего вы просто включаете ее как функцию 
активации Conv2D.
```python
model = keras.Sequential([
    layers.Conv2D(filters=64, kernel_size=3, activation='relu')
    # More layers follow
])
```
Вы можете думать о функции активации как о подсчете значений пикселей в соответствии с некоторой степенью важности. 
Активация ReLU говорит, что отрицательные значения не важны, и поэтому устанавливает их в 0. («Все неважное 
одинаково неважно»).  

Вот ReLU применил карты функций выше. Обратите внимание, как ему удается изолировать функции.

ReLU применяется к картам характеристик.
Как и другие функции активации, функция ReLU нелинейна. По сути, это означает, что общий эффект всех слоев в сети 
будет отличаться от того, что вы получили бы, просто сложив эффекты вместе, - что будет таким же, как то, что вы 
могли бы достичь только с одним слоем. Нелинейность гарантирует, что функции будут объединяться интересным образом 
по мере того, как они продвигаются вглубь сети. (Мы более подробно рассмотрим это «наложение признаков» в Уроке 5.)   

Пример - применение свертки и ReLU
В этом примере мы сделаем извлечение самостоятельно, чтобы лучше понять, что сверточные сети делают «за кулисами».
```python
import tensorflow as tf
import matplotlib.pyplot as plt
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')

image_path = '../input/computer-vision-resources/car_feature.jpg'
image = tf.io.read_file(image_path)
image = tf.io.decode_jpeg(image)

plt.figure(figsize=(6, 6))
plt.imshow(tf.squeeze(image), cmap='gray')
plt.axis('off')
plt.show();
```
Для этапа фильтрации мы определим ядро, а затем применим его со сверткой. Ядро в этом случае является ядром 
"обнаружения края". Вы можете определить его с помощью tf.constant, как если бы вы определяли массив в Numpy с 
помощью np.array. Это создает тензор сортировки, который использует TensorFlow.  

```python
import tensorflow as tf

kernel = tf.constant([
    [-1, -1, -1],
    [-1,  8, -1],
    [-1, -1, -1],
])

plt.figure(figsize=(3, 3))
show_kernel(kernel)
```
TensorFlow включает множество общих операций, выполняемых нейронными сетями, в свой модуль tf.nn. Два, которые мы 
будем использовать, - это conv2d и relu. Это просто функциональные версии слоев Keras. 

Следующая скрытая ячейка немного переформатирует, чтобы сделать вещи совместимыми с TensorFlow. Детали не важны для 
этого примера. 
```python
# Reformat for batch compatibility.
image = tf.image.convert_image_dtype(image, dtype=tf.float32)
image = tf.expand_dims(image, axis=0)
kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])
kernel = tf.cast(kernel, dtype=tf.float32)
```
Теперь применим наше ядро и посмотрим, что произойдет.

```python
image_filter = tf.nn.conv2d(
    input=image,
    filters=kernel,
    # we'll talk about these two in lesson 4!
    strides=1,
    padding='SAME',
)

plt.figure(figsize=(6, 6))
plt.imshow(tf.squeeze(image_filter))
plt.axis('off')
plt.show();
```
Далее идет этап обнаружения с функцией ReLU. Эта функция намного проще, чем свертка, поскольку у нее нет никаких 
параметров для установки. 

```python
image_detect = tf.nn.relu(image_filter)

plt.figure(figsize=(6, 6))
plt.imshow(tf.squeeze(image_detect))
plt.axis('off')
plt.show();
```
И теперь мы создали карту функций! Подобные изображения - это то, что голова использует для решения своей задачи 
классификации. Мы можем представить, что одни особенности могут быть более характерны для автомобилей, а другие - 
для грузовиков. Задача свёрточной сети во время обучения - создать ядра, которые могут находить эти функции.  

### Вывод
В этом уроке мы увидели первые два шага, которые использует convnet для извлечения признаков: фильтрация со слоями 
Conv2D и обнаружение с активацией relu. 


