### Custom Convnets
Введение
Теперь, когда вы увидели слои, которые использует свертка для извлечения функций, пришло время собрать их вместе и 
построить собственную сеть! 

### От простого к изысканному
В последних трех уроках мы увидели, как сверточные сети выполняют извлечение признаков с помощью трех операций: 
фильтрации, обнаружения и уплотнения. За один цикл извлечения признаков из изображения можно извлечь только 
относительно простые детали, такие как простые линии или контрасты. Они слишком просты для решения большинства 
проблем классификации. Вместо этого свертки будут повторять это извлечение снова и снова, так что функции становятся 
более сложными и уточненными по мере того, как они проникают в сеть.    

Характеристики, извлеченные из изображения автомобиля, от простых до изысканных.
Сверточные блоки
Он делает это, пропуская их через длинные цепочки сверточных блоков, которые выполняют это извлечение.

### Извлечение как последовательность блоков.
Эти сверточные блоки представляют собой стопки слоев Conv2D и MaxPool2D, роль которых в извлечении признаков мы 
узнали на последних нескольких уроках. 

Разновидность блока извлечения: свертка, ReLU, пулинг.
Каждый блок представляет собой раунд извлечения, и, составляя эти блоки, свёртка может комбинировать и 
рекомбинировать созданные функции, увеличивая их и формируя, чтобы они лучше соответствовали решаемой задаче. 
Глубокая структура современных сетей - это то, что позволяет создавать эти сложные функции и в значительной степени 
отвечает за их превосходную производительность.   

### Пример - разработка Convnet
Давайте посмотрим, как определить глубокую сверточную сеть, способную создавать сложные функции. В этом примере мы 
создадим модель Keras Sequence, а затем обучим ее на нашем наборе данных Cars. 

Шаг 1 - Загрузите данные
Эта скрытая ячейка загружает данные.

```python
# Imports
import os, warnings
import matplotlib.pyplot as plt
from matplotlib import gridspec

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

# Reproducability
def set_seed(seed=31415):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
set_seed()

# Set Matplotlib defaults
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')
warnings.filterwarnings("ignore") # to clean up output cells


# Load training and validation sets
ds_train_ = image_dataset_from_directory(
    '../input/car-or-truck/train',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)
ds_valid_ = image_dataset_from_directory(
    '../input/car-or-truck/valid',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=False,
)

# Data Pipeline
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = (
    ds_train_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
ds_valid = (
    ds_valid_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
```
Шаг 2 - Определите модель
Вот схема модели, которую мы будем использовать:

Схема сверточной модели.
Теперь определим модель. Посмотрите, как наша модель состоит из трех блоков слоев Conv2D и MaxPool2D (базовый), за 
которыми следует заголовок из плотных слоев. Мы можем более или менее напрямую перевести эту диаграмму в модель 
Keras Sequential, просто заполнив соответствующие параметры.  

```python
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([

    # First Convolutional Block
    layers.Conv2D(filters=32, kernel_size=5, activation="relu", padding='same',
                  # give the input dimensions in the first layer
                  # [height, width, color channels(RGB)]
                  input_shape=[128, 128, 3]),
    layers.MaxPool2D(),

    # Second Convolutional Block
    layers.Conv2D(filters=64, kernel_size=3, activation="relu", padding='same'),
    layers.MaxPool2D(),

    # Third Convolutional Block
    layers.Conv2D(filters=128, kernel_size=3, activation="relu", padding='same'),
    layers.MaxPool2D(),

    # Classifier Head
    layers.Flatten(),
    layers.Dense(units=6, activation="relu"),
    layers.Dense(units=1, activation="sigmoid"),
])
model.summary()
```
Обратите внимание, что в этом определении количество фильтров удваивается поблочно: 64, 128, 256. Это общий шаблон. 
Поскольку слой MaxPool2D уменьшает размер функциональных карт, мы можем позволить себе увеличить количество, которое 
мы создаем.  

### Шаг 3 - Тренируйтесь
Мы можем обучить эту модель так же, как модель из Урока 1: скомпилировать ее с помощью оптимизатора вместе с 
потерями и метрикой, подходящими для двоичной классификации. 
```python
model.compile(
    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),
    loss='binary_crossentropy',
    metrics=['binary_accuracy']
)

history = model.fit(
    ds_train,
    validation_data=ds_valid,
    epochs=40,
    verbose=0,
)
```

```python
import pandas as pd

history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();
```


Эта модель намного меньше, чем модель VGG16 из Урока 1 - всего 3 сверточных слоя по сравнению с 16 в VGG16. Тем не 
менее, он смог довольно хорошо вписаться в этот набор данных. Возможно, мы все еще сможем улучшить эту простую 
модель, добавив больше сверточных слоев, надеясь создать функции, лучше адаптированные к набору данных. Это то, что 
мы попробуем в упражнениях.   

### Вывод
В этом руководстве вы узнали, как создать настраиваемую свертку, состоящую из множества сверточных блоков и 
способную разрабатывать сложные функции. 
