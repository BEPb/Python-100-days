Creating Features
###Вступление
После того, как вы определили набор функций с некоторым потенциалом, пора приступить к их разработке. В этом уроке 
вы узнаете ряд общих преобразований, которые можно выполнять полностью в Pandas. 

В этом уроке мы будем использовать четыре набора данных с различными типами объектов: Дорожно-транспортные 
происшествия в США, Автомобили 1985 года, Конкретные составы и Пожизненная ценность клиента. Следующая скрытая 
ячейка загружает их.

```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

plt.style.use("seaborn-whitegrid")
plt.rc("figure", autolayout=True)
plt.rc(
    "axes",
    labelweight="bold",
    labelsize="large",
    titleweight="bold",
    titlesize=14,
    titlepad=10,
)

accidents = pd.read_csv("../input/fe-course-data/accidents.csv")
autos = pd.read_csv("../input/fe-course-data/autos.csv")
concrete = pd.read_csv("../input/fe-course-data/concrete.csv")
customer = pd.read_csv("../input/fe-course-data/customer.csv")
```

###Советы по открытию новых возможностей
Разберитесь в особенностях. Обратитесь к документации по вашему набору данных, если таковая имеется.
Изучите проблемную область, чтобы получить знания в этой области. Если ваша проблема заключается в прогнозировании 
цен на жилье, поищите, например, недвижимость. Википедия может быть хорошей отправной точкой, но книги и журнальные 
статьи часто содержат лучшую информацию.


Изучите предыдущую работу. Описания решений с прошлых конкурсов Kaggle - отличный ресурс.
Используйте визуализацию данных. Визуализация может выявить патологии в распределении функции или сложные отношения,
которые можно упростить. Обязательно визуализируйте свой набор данных в процессе разработки функций.



###Математические преобразования
Взаимосвязи между числовыми характеристиками часто выражаются математическими формулами, с которыми вы часто будете 
сталкиваться при исследовании своей предметной области. В Pandas вы можете применять арифметические операции к 
столбцам, как если бы они были обычными числами.

В наборе данных Automobile есть функции, описывающие двигатель автомобиля. Исследования дают множество формул для 
создания потенциально полезных новых функций. Например, "коэффициент хода" является мерой того, насколько 
эффективен двигатель по сравнению с его производительностью:

```python
autos["stroke_ratio"] = autos.stroke / autos.bore

autos[["stroke", "bore", "stroke_ratio"]].head()
```
Чем сложнее комбинация, тем сложнее будет модели для изучения, например, этой формулы для «смещения» двигателя, 
меры его мощности:

```python
autos["displacement"] = (
    np.pi * ((0.5 * autos.bore) ** 2) * autos.stroke * autos.num_of_cylinders
)
``` 

Визуализация данных может предлагать преобразования, часто «изменение формы» функции с помощью степеней или 
логарифмов. Например, распределение WindSpeed в ДТП в США сильно искажено. В этом случае логарифм эффективен для 
его нормализации:

```python
# If the feature has 0.0 values, use np.log1p (log(1+x)) instead of np.log
# Если функция имеет значения 0.0, используйте np.log1p (log (1 + x)) вместо np.log
accidents["LogWindSpeed"] = accidents.WindSpeed.apply(np.log1p)

# Plot a comparison
# Постройте сравнение
fig, axs = plt.subplots(1, 2, figsize=(8, 4))
sns.kdeplot(accidents.WindSpeed, shade=True, ax=axs[0])
sns.kdeplot(accidents.LogWindSpeed, shade=True, ax=axs[1]);
```

Ознакомьтесь с нашим уроком по нормализации в Очистке данных, где вы также узнаете о преобразовании Бокса-Кокса, 
очень общем виде нормализатора.

###Подсчитывает
Характеристики, описывающие наличие или отсутствие чего-либо, часто входят в наборы, например, набор факторов риска 
заболевания. Вы можете агрегировать такие характеристики, создав счетчик.

Эти функции будут двоичными (1 - присутствует, 0 - отсутствует) или логическими (True или False). В Python 
логические значения можно складывать так же, как если бы они были целыми числами.

В дорожно-транспортных происшествиях есть несколько функций, указывающих, был ли какой-либо объект проезжей части 
рядом с аварией. Это позволит подсчитать общее количество объектов дороги поблизости с использованием метода суммы:
```python
roadway_features = ["Amenity", "Bump", "Crossing", "GiveWay",
    "Junction", "NoExit", "Railway", "Roundabout", "Station", "Stop",
    "TrafficCalming", "TrafficSignal"]
accidents["RoadwayFeatures"] = accidents[roadway_features].sum(axis=1)

accidents[roadway_features + ["RoadwayFeatures"]].head(10)
```

###Особенности наращивания и разрушения
Часто у вас будут сложные строки, которые можно разбить на более простые части. Несколько распространенных примеров:

```python
components = [ "Cement", "BlastFurnaceSlag", "FlyAsh", "Water",
               "Superplasticizer", "CoarseAggregate", "FineAggregate"]
concrete["Components"] = concrete[components].gt(0).sum(axis=1)

concrete[components + ["Components"]].head(10)
```

Подобные функции часто имеют некоторую структуру, которую вы можете использовать. Например, в телефонных номерах в 
США есть код города (часть «(999)»), который сообщает вам местонахождение звонящего. Как всегда, здесь могут 
окупиться некоторые исследования.

Аксессор str позволяет применять строковые методы, такие как split, непосредственно к столбцам. Набор данных 
Customer Lifetime Value содержит характеристики, описывающие клиентов страховой компании. С помощью функции 
политики мы могли бы отделить тип от уровня покрытия:

```python
customer[["Type", "Level"]] = (  # Create two new features
    customer["Policy"]           # from the Policy feature
    .str                         # through the string accessor
    .split(" ", expand=True)     # by splitting on " "
                                 # and expanding the result into separate columns
)

customer[["Policy", "Type", "Level"]].head(10)
```

Вы также можете объединить простые функции в составную функцию, если у вас есть основания полагать, что в этой 
комбинации было какое-то взаимодействие:

```python
autos["make_and_style"] = autos["make"] + "_" + autos["body_style"]
autos[["make", "body_style", "make_and_style"]].head()
```


###Групповые преобразования
Наконец, у нас есть групповые преобразования, которые собирают информацию по нескольким строкам, сгруппированным по 
некоторой категории. С помощью группового преобразования вы можете создавать такие функции, как «средний доход 
штата проживания человека» или «доля фильмов, выпущенных в будний день, по жанрам». Если вы обнаружили 
взаимодействие категорий, групповое преобразование этой категории может оказаться полезным для исследования.

Используя функцию агрегирования, групповое преобразование объединяет две функции: категориальную функцию, которая 
обеспечивает группировку, и другую функцию, значения которой вы хотите агрегировать. Для «среднего дохода по 
штатам» вы должны выбрать «Состояние» для функции группировки, среднее значение для функции агрегирования и «Доход» 
для агрегированной функции. Чтобы вычислить это в Pandas, мы используем методы groupby и transform:

```python
customer["AverageIncome"] = (
    customer.groupby("State")  # for each state
    ["Income"]                 # select the income
    .transform("mean")         # and compute its mean
)

customer[["State", "Income", "AverageIncome"]].head(10)
```

клиент [["Состояние", "Доход", "Средний доход"]]. Глава (10)
Государственный доход Средний доход
0 Вашингтон 56274 38122.733083
1 Аризона 0 37405.402231
2 Невада 48767 38369.605442
3 Калифорния 0 37558.946667
4 Вашингтон 43836 38122.733083
5 Орегон 62902 37557.283353
6 Орегон 55350 37557.283353
7 Аризона 0 37405.402231
8 Орегон 14072 37557,283353
9 Орегон 28812 37557.283353

Функция mean - это встроенный метод фрейма данных, что означает, что мы можем передать его как строку для 
преобразования. Другие удобные методы включают max, min, median, var, std и count. Вот как можно рассчитать частоту,
с которой каждое состояние встречается в наборе данных:

```python
customer["StateFreq"] = (
    customer.groupby("State")
    ["State"]
    .transform("count")
    / customer.State.count()
)

customer[["State", "StateFreq"]].head(10)
```

заказчик [["State", "StateFreq"]]. head (10)
Состояние StateFreq
0 Вашингтон 0,087366
1 Аризона 0,186446
2 Невада 0,096562
3 Калифорния 0,344865
4 Вашингтон 0,087366
5 Орегон 0,284760
6 Орегон 0,284760
7 Аризона 0,186446
8 Орегон 0,284760
9 Орегон 0,284760



Вы можете использовать подобное преобразование, чтобы создать «частотное кодирование» для категориальной функции.

Если вы используете обучающие и проверочные разбиения, чтобы сохранить их независимость, лучше всего создать 
сгруппированный объект, используя только обучающий набор, а затем присоединить его к проверочному набору. Мы можем 
использовать метод слияния набора проверки после создания уникального набора значений с drop_duplicates на 
обучающем наборе:

```python
# Create splits
# Создать сплиты
df_train = customer.sample(frac=0.5)
df_valid = customer.drop(df_train.index)

# Create the average claim amount by coverage type, on the training set
# Создайте среднюю сумму претензии по типу покрытия на обучающем наборе
df_train["AverageClaim"] = df_train.groupby("Coverage")["ClaimAmount"].transform("mean")

# Merge the values into the validation set
# Объединить значения в набор проверки
df_valid = df_valid.merge(
    df_train[["Coverage", "AverageClaim"]].drop_duplicates(),
    on="Coverage",
    how="left",
)

df_valid[["Coverage", "AverageClaim"]].head(10)
```


Покрытие Среднее
0 Базовый 378,258136
1 Расширенная 473.676972
2 Премиум 644.674427
3 Базовый 378.258136
4 Расширенный 473.676972
5 Базовый 378.258136
6 Базовый 378.258136
7 Базовый 378.258136
8 Базовый 378.258136
9 Базовый 378.258136

###Советы по созданию элементов
- При создании элементов полезно помнить о сильных и слабых сторонах вашей модели. Вот несколько рекомендаций:
- Линейные модели учат суммы и разности естественным образом, но не могут изучить ничего более сложного. 
- Похоже, что большинству моделей сложно изучить соотношения. Комбинации соотношений часто приводят к небольшому 
  увеличению производительности.
- Линейные модели и нейронные сети обычно лучше справляются с нормализованными функциями. Нейронные сети особенно 
  нуждаются в функциях, масштабируемых до значений, не слишком далеких от 0. Древовидные модели (например, 
  случайные леса и XGBoost) иногда могут выиграть от нормализации, но обычно в гораздо меньшей степени.
- Древовидные модели могут научиться приближать практически любую комбинацию функций, но когда комбинация особенно 
  важна, они все равно могут извлечь выгоду из ее явного создания, особенно когда данные ограничены.
- Подсчет особенно полезен для древовидных моделей, поскольку в этих моделях нет естественного способа агрегирования 
  информации сразу по многим функциям.
