Pipelines
### Трубопроводы
В этом руководстве вы узнаете, как использовать конвейеры для очистки кода моделирования.

### Вступление
Конвейеры - это простой способ упорядочить код предварительной обработки данных и моделирования. В частности, 
конвейер связывает этапы предварительной  обработки и моделирования, поэтому вы можете использовать весь пакет, как 
если бы это был один этап.

Многие специалисты по обработке данных собирают модели без конвейеров, но конвейеры имеют некоторые важные 
преимущества. К ним относятся:

1. Более чистый код: учет данных на каждом этапе предварительной обработки может стать беспорядочным. С конвейером вам 
не нужно вручную отслеживать данные обучения и проверки на каждом этапе.
2. Меньше ошибок: меньше возможностей неправильно применить шаг или забыть шаг предварительной обработки.
3. Легче в производстве: может быть на удивление сложно перейти от прототипа модели к чему-то масштабируемому. Мы не 
   будем вдаваться в подробности, связанные с этим, но конвейеры могут помочь.
4. Дополнительные параметры для проверки модели: в следующем руководстве вы увидите пример, в котором рассматривается 
   перекрестная проверка.

###Пример
Как и в предыдущем руководстве, мы будем работать с набором данных Melbourne Housing.

Мы не будем заострять внимание на этапе загрузки данных. Вместо этого вы можете представить, что находитесь в точке,
где у вас уже есть данные для обучения и проверки в X_train, X_valid, y_train и y_valid.

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Read the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Separate target from predictors
y = data.Price
X = data.drop(['Price'], axis=1)

# Divide data into training and validation subsets
X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,
                                                                random_state=0)

# "Cardinality" means the number of unique values in a column
# Select categorical columns with relatively low cardinality (convenient but arbitrary)
categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and 
                        X_train_full[cname].dtype == "object"]

# Select numerical columns
numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]

# Keep selected columns only
my_cols = categorical_cols + numerical_cols
X_train = X_train_full[my_cols].copy()
X_valid = X_valid_full[my_cols].copy()
```

Мы взглянем на данные обучения с помощью метода head () ниже. Обратите внимание, что данные содержат как 
категориальные данные, так и столбцы с пропущенными значениями. С конвейером легко справиться и с тем, и с другим!

```X_train.head ()```

Мы строим полный трубопровод в три этапа.

###Шаг 1. Определите шаги предварительной обработки
Подобно тому, как конвейер объединяет этапы предварительной обработки и моделирования, мы используем класс 
ColumnTransformer для объединения различных этапов предварительной обработки. Код ниже:
- вменяет недостающие значения в числовые данные, и
- вменяет пропущенные значения и применяет быстрое кодирование к категориальным данным.
```python
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder

# Preprocessing for numerical data
# Предварительная обработка числовых данных
numerical_transformer = SimpleImputer(strategy='constant')

# Preprocessing for categorical data
# Предварительная обработка категориальных данных
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Bundle preprocessing for numerical and categorical data
# Предварительная обработка пакетов для числовых и категориальных данных
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])
```

###Шаг 2: Определите модель
Затем мы определяем модель случайного леса с помощью знакомого класса RandomForestRegressor.

```python
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=0)
```

модель = RandomForestRegressor (n_estimators = 100, random_state = 0)
###Шаг 3. Создайте и оцените конвейер
Наконец, мы используем класс Pipeline для определения конвейера, который объединяет этапы предварительной обработки и моделирования. Обратите внимание на несколько важных моментов:

- С помощью конвейера мы предварительно обрабатываем данные обучения и подгоняем модель в одну строку кода. (Напротив,
без конвейера мы должны выполнять вменение, однократное кодирование и обучение модели на отдельных этапах. Это становится особенно беспорядочным, если нам приходится иметь дело как с числовыми, так и с категориальными переменными!)
- С помощью конвейера мы передаем необработанные функции в X_valid команде предсказать (), и конвейер автоматически 
  выполняет предварительную обработку функций перед генерацией прогнозов. (Однако без конвейера мы должны помнить о предварительной обработке данных проверки перед тем, как делать прогнозы.)
```python
from sklearn.metrics import mean_absolute_error

# Bundle preprocessing and modeling code in a pipeline
# Объединение кода предварительной обработки и моделирования в конвейер
my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('model', model)
                             ])

# Preprocessing of training data, fit model 
# Предварительная обработка обучающих данных, подгонка модели
my_pipeline.fit(X_train, y_train)

# Preprocessing of validation data, get predictions
# Предварительная обработка данных валидации, получение прогнозов
preds = my_pipeline.predict(X_valid)

# Evaluate the model
# Оценить модель
score = mean_absolute_error(y_valid, preds)
print('MAE:', score)
```
MAE: 160679.18917034855
### Заключение
Конвейеры полезны для очистки кода машинного обучения и предотвращения ошибок и особенно полезны для рабочих 
процессов со сложной предварительной обработкой данных.
