###Cross-Validation
В этом руководстве вы узнаете, как использовать перекрестную проверку для лучшего измерения производительности модели.

### Вступление
Машинное обучение - это итеративный процесс.

Вы столкнетесь  с выбором того, какие прогностические переменные использовать, какие типы моделей использовать, 
какие аргументы  предоставить этим моделям и т. Д. До сих пор вы делали этот выбор на основе данных, измеряя 
качество модели с помощью проверки ( или задержка) установлен.

Но у этого подхода  есть свои недостатки. Чтобы убедиться в этом, представьте, что у вас есть набор данных с 5000 
строками. Обычно  вы храните около 20% данных в виде набора данных для проверки или 1000 строк. Но это оставляет 
некоторый случайный  шанс при определении оценок модели. То есть модель может хорошо работать с одним набором из 
1000 строк, даже  если она будет неточной для других 1000 строк.

В крайнем случае,  вы можете представить себе, что в наборе проверки имеется только одна строка данных. Если вы 
сравните альтернативные  модели, то какая из них дает наилучшие прогнозы для одной точки данных, будет в основном 
удачей!

В общем, чем больше  набор для проверки, тем меньше случайности (или «шума») в нашей оценке качества модели и тем 
надежнее она будет.  К сожалению, мы можем получить большой набор проверок, только удалив строки из наших обучающих 
данных, а меньшие наборы обучающих данных означают худшие модели!

### Что такое перекрестная проверка?
При перекрестной проверке мы запускаем процесс моделирования на разных подмножествах данных, чтобы получить несколько показателей качества модели.

Например, мы могли бы начать с разделения данных на 5 частей, каждая по 20% от полного набора данных. В этом случае 
мы говорим, что разбили данные на 5 частей.

Затем мы запускаем по одному эксперименту для каждой складки:

- В эксперименте 1 мы используем первую свертку в качестве набора для проверки (или удержания), а все остальное - в 
качестве обучающих данных. Это дает нам оценку качества модели, основанную на наборе выдержек 20%.
- В эксперименте 2 мы извлекаем данные из второй складки (и используем все, кроме второй, для обучения модели). Затем 
  набор задержек используется для получения второй оценки качества модели.
Мы повторяем этот процесс, используя каждую складку по одному разу в качестве удерживающего набора. Собирая все это вместе, в какой-то момент 100% данных используется в качестве удержания, и мы получаем показатель качества модели, основанный на всех строках в наборе данных (даже если мы не используем все строки одновременно). .
###Когда следует использовать перекрестную проверку?
Перекрестная проверка дает более точную оценку качества модели, что особенно важно, если вы принимаете много решений по моделированию. Однако его выполнение может занять больше времени, поскольку он оценивает несколько моделей (по одной для каждой складки).

Итак, с учетом этих компромиссов, когда следует использовать каждый подход?

- Для небольших наборов данных, где дополнительная вычислительная нагрузка не является большой проблемой, следует 
выполнить перекрестную проверку.
- Для больших наборов данных достаточно одного набора для проверки. Ваш код будет работать быстрее, и у вас может 
  быть достаточно данных, поэтому нет необходимости повторно использовать некоторые из них для задержки.
Не существует простого порогового значения для определения большого и малого набора данных. Но если для запуска вашей модели требуется пара минут или меньше, вероятно, стоит перейти на перекрестную проверку.

Кроме того, вы можете запустить перекрестную проверку и посмотреть, близки ли результаты каждого эксперимента. Если каждый эксперимент дает одинаковые результаты, вероятно, достаточно одного набора для проверки.

###Пример
Мы будем работать с теми же данными, что и в предыдущем уроке. Мы загружаем входные данные в X и выходные данные в y.
```python
import pandas as pd

# Read the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Select subset of predictors
cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# Select target
y = data.Price
```
Затем мы определяем конвейер, который использует импьютер для заполнения отсутствующих значений и случайную модель леса для прогнозирования.

Хотя кросс-проверку можно проводить без конвейеров, это довольно сложно! Использование конвейера значительно 
упростит код.

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])
```

                        
Мы получаем оценки перекрестной проверки с помощью функции cross_val_score () из scikit-learn. Мы устанавливаем количество складок параметром cv.

```python
from sklearn.model_selection import cross_val_score

# Multiply by -1 since sklearn calculates *negative* MAE
# Умножаем на -1, так как sklearn вычисляет * отрицательное * MAE
scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5,
                              scoring='neg_mean_absolute_error')

print("MAE scores:\n", scores)
```
Показатели MAE:
 [301628.7893587 303164.4782723 287298.331666 236061.84754543
 260383.45111427]


Параметр скоринга выбирает меру качества модели для отчета: в этом случае мы выбрали отрицательную среднюю абсолютную ошибку (MAE). Документы для scikit-learn показывают список опций.

Немного удивительно, что мы указываем отрицательную MAE. В Scikit-learn есть соглашение, в котором определены все показатели, поэтому лучше использовать большее число. Использование здесь негативов позволяет им быть последовательными.
с этим условием, хотя отрицательный MAE почти не слышен где-либо еще.

Обычно нам нужен единый показатель качества модели для сравнения альтернативных моделей. Итак, мы берем среднее значение по экспериментам.

```print ("Средняя оценка MAE (по экспериментам):")```
печать (scores.mean ())
Средний балл MAE (по экспериментам):
277707.3795913405
###Заключение
Использование перекрестной проверки дает гораздо лучший показатель качества модели с дополнительным преимуществом 
очистки нашего кода: обратите внимание, что нам больше не нужно отслеживать отдельные наборы для обучения и 
проверки. Так что, особенно для небольших наборов данных, это хорошее улучшение! 




























