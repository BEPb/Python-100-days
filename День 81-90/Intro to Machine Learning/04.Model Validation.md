## Model Validation

Вы построили модель. Но насколько это хорошо?

В этом уроке вы научитесь использовать проверку модели для измерения качества вашей модели. Измерение качества 
модели - ключ к многократному улучшению ваших моделей.

### Что такое проверка модели
Вы захотите оценить почти каждую модель, которую вы когда-либо строили. В большинстве (хотя и не во всех) 
приложениях важным показателем качества модели является точность прогнозов. Другими словами, будут ли прогнозы 
модели близки к тому, что происходит на самом деле.

Многие люди совершают огромную ошибку при измерении точности прогнозов. Они делают прогнозы на основе своих данных 
обучения и сравнивают эти прогнозы с целевыми значениями в данных обучения. Вы увидите проблему с этим подходом и 
то, как ее решить через мгновение, но давайте сначала подумаем о том, как мы это сделаем.

Сначала вам нужно подытожить качество модели в понятной форме. Если вы сравните прогнозируемую и фактическую 
стоимость домов для 10 000 домов, вы, вероятно, найдете смесь хороших и плохих прогнозов. Просматривать список из 
10 000 прогнозируемых и фактических значений бессмысленно. Нам нужно свести это в единую метрику.

Существует множество показателей для оценки качества модели, но мы начнем с одной, называемой средней абсолютной 
ошибкой (также называемой MAE). Давайте разберем этот показатель, начиная с последнего слова - ошибка.

Ошибка прогноза для каждого дома:
```python
error=actual−predicted
```
Итак, если дом стоит 150 000 долларов, а вы предсказали, что он будет стоить 100 000 долларов, ошибка составит 50 
000 долларов.

С помощью метрики MAE мы берем абсолютное значение каждой ошибки. Это преобразует каждую ошибку в положительное 
число. Затем мы берем среднее значение этих абсолютных ошибок. Это наша мера качества модели.

```python
# Data Loading Code Hidden Here
import pandas as pd

# Load data
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
# Filter rows with missing price values
filtered_melbourne_data = melbourne_data.dropna(axis=0)
# Choose target and features
y = filtered_melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 
                        'YearBuilt', 'Lattitude', 'Longtitude']
X = filtered_melbourne_data[melbourne_features]

from sklearn.tree import DecisionTreeRegressor
# Define model
melbourne_model = DecisionTreeRegressor()
# Fit model
melbourne_model.fit(X, y)
```

Когда у нас есть модель, мы вычисляем среднюю абсолютную ошибку следующим образом:

```python
from sklearn.metrics import mean_absolute_error

predicted_home_prices = melbourne_model.predict(X)
mean_absolute_error(y, predicted_home_prices)
```
### Проблема с оценками "в выборке"
Только что вычисленный показатель можно назвать оценкой "в выборке". Мы использовали один «образец» домов как для 
построения модели, так и для ее оценки. Вот почему это плохо.

Представьте, что на большом рынке недвижимости цвет двери не связан с ценой дома.
Однако в выборке данных, которую вы использовали для построения модели, все дома с зелеными дверями были очень 
дорогими. Задача модели - найти закономерности, предсказывающие цены на жилье, чтобы они видели эту закономерность 
и всегда предсказывали высокие цены на дома с зелеными дверями.
Поскольку этот шаблон был получен из обучающих данных, модель будет выглядеть точной в обучающих данных.
Но если этот шаблон не выполняется, когда модель видит новые данные, модель будет очень неточной при использовании 
на практике.
Поскольку практическая ценность моделей заключается в прогнозировании новых данных, мы измеряем производительность 
на данных, которые не использовались для построения модели. Самый простой способ сделать это - исключить некоторые 
данные из процесса построения модели, а затем использовать их для проверки точности модели на данных, которые она 
раньше не видела. Эти данные называются данными проверки.


### Кодирование
В библиотеке scikit-learn есть функция train_test_split для разделения данных на две части. Мы будем использовать 
некоторые из этих данных в качестве обучающих данных, чтобы соответствовать модели, а другие данные мы будем 
использовать в качестве данных проверки для вычисления mean_absolute_error.

Вот код:
```python
from sklearn.model_selection import train_test_split

# разделить данные на данные для обучения и проверки, как для функций, так и для цели
# Разделение основано на генераторе случайных чисел. Подача числового значения в
# аргумент random_state гарантирует, что мы получим одно и то же разбиение каждый раз, когда
# запускаем этот скрипт.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
# Определить модель
melbourne_model = DecisionTreeRegressor()
# приспосабливаем модель
melbourne_model.fit(train_X, train_y)

# получить прогнозируемые цены по данным проверки
val_predictions = melbourne_model.predict(val_X)
print(mean_absolute_error(val_y, val_predictions))
```

Ух ты!
Ваша средняя абсолютная ошибка для данных в выборке составила около 500 долларов. Вне выборки более 250 тысяч долларов.
В этом разница между моделью, которая почти идеально подходит, и моделью, непригодной для большинства практических 
целей. Для справки, средняя стоимость дома по данным проверки составляет 1,1 миллиона долларов. Таким образом, 
ошибка в новых данных составляет около четверти средней стоимости дома.
Есть много способов улучшить эту модель, например, поэкспериментировать, чтобы найти лучшие функции или разные типы 
моделей.

### Резюме
Вы построили модель. В этом упражнении вы проверите, насколько хороша ваша модель.

Запустите ячейку ниже, чтобы настроить среду кодирования там, где было остановлено предыдущее упражнение.
```python
# Code you have previously used to load data
import pandas as pd
from sklearn.tree import DecisionTreeRegressor

# Path of the file to read
iowa_file_path = '../input/home-data-for-ml-course/train.csv'

home_data = pd.read_csv(iowa_file_path)
y = home_data.SalePrice
feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
X = home_data[feature_columns]

# Specify Model
iowa_model = DecisionTreeRegressor()
# Fit Model
iowa_model.fit(X, y)

print("First in-sample predictions:", iowa_model.predict(X.head()))
print("Actual target values for those homes:", y.head().tolist())

# Set up code checking
from learntools.core import binder
binder.bind(globals())
from learntools.machine_learning.ex4 import *
print("Setup Complete")
```

### Упражнения
Шаг 1. Разделите данные
Используйте функцию train_test_split, чтобы разделить ваши данные.

Дайте ему аргумент random_state = 1, чтобы функции проверки знали, чего ожидать при проверке вашего кода.

Напомним, ваши функции загружаются в DataFrame X, а ваша цель загружается в y.

```python
# Import the train_test_split function and uncomment
from sklearn.model_selection import train_test_split

# fill in and uncomment
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
```

### Шаг 2: укажите и установите модель
Создайте модель DecisionTreeRegressor и подгоните ее к соответствующим данным. При создании модели снова установите 
random_state в 1.
```python
# Вы импортировали DecisionTreeRegressor в своем последнем упражнении.
# и этот код был скопирован в код настройки выше. Итак, не нужно
# импортировать снова

# Specify the model
iowa_model = DecisionTreeRegressor(random_state=1)

# Fit iowa_model with the training data.
iowa_model.fit(train_X, train_y)

```
###Шаг 3. Делайте прогнозы с данными проверки¶
```python
# Прогнозировать со всеми проверочными наблюдениями
val_predictions = iowa_model.predict(val_X)
```
Изучите свои прогнозы и фактические значения на основе данных проверки.

```python
# print the top few validation predictions
# несколько лучших проверочных прогнозов
print(y.head())
# print the top few actual prices from validation data
print(X.head())

```

###Шаг 4: Рассчитайте среднюю абсолютную ошибку в данных проверки

```python
from sklearn.metrics import mean_absolute_error
val_mae = ____

# uncomment following line to see the validation_mae
val_mae = mean_absolute_error(val_y, val_predictions)
print(val_mae)

```