# Text Classification
# Классификация естественного языка
# Вы проделали такую большую работу для ресторана DeFalco в предыдущем упражнении, что шеф-повар нанял вас для нового проекта.
#
# В меню ресторана есть адрес электронной почты, по которому посетители могут оставить отзыв о своей еде.
#
# Менеджер хочет, чтобы вы создали инструмент, который автоматически отправляет ему все отрицательные отзывы, чтобы он мог их исправить, и автоматически отправляет все положительные отзывы владельцу, чтобы менеджер мог попросить прибавку.
#
# Сначала вы создадите модель, чтобы отличать положительные отзывы от отрицательных, используя обзоры Yelp,
# потому что эти обзоры включают оценку с каждым обзором. Ваши данные состоят из текста каждого отзыва и рейтинга в
# звездах. Оценки с 1-2 звездами считаются «отрицательными», а оценки с 4-5 звездами - «положительными». Оценки с 3
# звездами являются «нейтральными» и исключены из данных.
# Любой способ создания проблемы машинного обучения будет иметь множество сильных и слабых сторон. Возможно,
# вы думали о других проблемах, кроме перечисленных здесь.
#
# Сила этого подхода заключается в том, что он позволяет отличать положительные электронные письма от отрицательных,
# даже если у вас нет исторических писем, которые вы пометили как положительные или отрицательные.
#
# Слабость этого подхода заключается в том, что электронные письма могут систематически отличаться от обзоров Yelp,
# что делает вашу модель менее точной. Например, клиенты обычно могут использовать разные слова или сленг в
# электронных письмах, и модель, основанная на обзорах Yelp, не увидит эти слова.
#
# Если вы хотите увидеть, насколько серьезна эта проблема, вы можете сравнить частоты слов в двух источниках. На
# практике может быть достаточно вручную прочитать несколько писем из каждого источника, чтобы увидеть, серьезная ли
# это проблема.
#
# Если вы хотите сделать что-то более интересное, вы можете создать набор данных, содержащий как обзоры Yelp,
# так и электронные письма, и посмотреть, может ли модель отличить источник отзывов от текстового содержимого. В
# идеале вы хотели бы обнаружить, что эта модель не работает хорошо, потому что это будет означать,
# что ваши источники данных похожи. Здесь такой подход кажется излишне сложным.


# Шаг 2. Просмотрите данные и создайте модель¶
# Двигаясь вперед со своим планом, вам нужно будет загрузить данные. Вот базовый код для загрузки данных и разделения
# их на набор для обучения и проверки. Запустите этот код.
def load_data(csv_file, split=0.9):
    data = pd.read_csv(csv_file)

    # Shuffle data
    train_data = data.sample(frac=1, random_state=7)

    texts = train_data.text.values
    labels = [{"POSITIVE": bool(y), "NEGATIVE": not bool(y)}
              for y in train_data.sentiment.values]
    split = int(len(train_data) * split)

    train_labels = [{"cats": labels} for labels in labels[:split]]
    val_labels = [{"cats": labels} for labels in labels[split:]]

    return texts[:split], train_labels, texts[split:], val_labels


train_texts, train_labels, val_texts, val_labels = load_data('../input/nlp-course/yelp_ratings.csv')

# Вы будете использовать эти обучающие данные для построения модели. Код для построения модели такой же, как и в учебнике. Так что это скопировано для вас ниже.
#
# Сначала запустите ячейку ниже, чтобы посмотреть на пару элементов из ваших данных обучения.
print('Texts from training data\n------')
print(train_texts[:2])
print('\nLabels from training data\n------')
print(train_labels[:2])

# Но поскольку ваши данные отличаются, в ячейке кода моделирования есть две строки, которые вам нужно изменить. Вы можете понять, что это такое?
#
# Если вы не уверены, взгляните еще раз на данные и обратите особое внимание на метки, которые следует вводить в
# классификатор текста.
import spacy

# Create an empty model
nlp = spacy.blank("en")

# Add the TextCategorizer to the empty model
textcat = nlp.add_pipe("textcat")

# Add labels to text classifier
textcat.add_label("NEGATIVE")
textcat.add_label("POSITIVE")

# Шаг 3: функция обучения
# Реализуйте функцию train, которая обновляет модель обучающими данными. По большей части это общий сбор данных, который мы за вас заполнили.
#
# Просто добавьте одну строку кода, необходимую для обновления вашей модели.
import random
from spacy.util import minibatch
from spacy.training.example import Example

def train(model, train_data, optimizer, batch_size=8):
    losses = {}
    random.seed(1)
    random.shuffle(train_data)

    for batch in minibatch(train_data, size=batch_size):
        for text, labels in batch:
            doc = nlp.make_doc(text)
            example = Example.from_dict(doc, labels)
            # Update model with texts and labels
            model.update([example], sgd=optimizer, losses=losses)

    return losses

# Fix seed for reproducibility
spacy.util.fix_random_seed(1)
random.seed(1)

# This may take a while to run!
optimizer = nlp.begin_training()
train_data = list(zip(train_texts, train_labels))
losses = train(nlp, train_data, optimizer)
print(losses['textcat'])

text = "This tea cup was full of holes. Do not recommend."
doc = nlp(text)
print(doc.cats)

# Шаг 4: Прогнозы
# Реализуйте функцию прогнозирования, которая предсказывает тональность текстовых примеров.
#
# Сначала токенизируйте тексты с помощью nlp.tokenizer ().
# Затем передайте эти документы в TextCategorizer, который вы можете получить из nlp.get_pipe ().
# Используйте метод textcat.predict (), чтобы получить оценки для каждого документа, затем выберите класс с наивысшей
# оценкой (вероятностью) в качестве прогнозируемого класса.
def predict(nlp, texts):
    # Use the model's tokenizer to tokenize each input text
    docs = [nlp.tokenizer(text) for text in texts]

    # Use textcat to get the scores for each doc
    textcat = nlp.get_pipe("textcat")
    scores = textcat.predict(docs)

    # From the scores, find the class with the highest score/probability
    predicted_class = scores.argmax(axis=1)

    return predicted_class

texts = val_texts[34:38]
predictions = predict(nlp, texts)

for p, t in zip(predictions, texts):
    print(f"{textcat.labels[p]}: {t} \n")
# ПОЗИТИВНО: подошли, заказали обеденное сочетание «Выбери 2» и выбрали самый продаваемый сэндвич с курицей 1/2 и киноа. Оба были вкусными, куриный салат немного сливочный, но был идеальным с киноа на стороне. Это хорошее место для обеда, непринужденное и чистое!
#
# ПОЛОЖИТЕЛЬНО: Был здесь вчера вечером и купил устриц, жареную окра, картофель фри и луковые кольца. Я не могу жаловаться. Порции были отличными и вкусными !!! Я обязательно вернусь, чтобы узнать больше. Не могу дождаться, чтобы попробовать буден из раков и краба в мягком панцире.
#
# ПОЗИТИВНО: Этот ресторан был фантастическим!
# Идея еды без видения была интригующей. Обед был наполнен смехом и хорошей беседой.
#
# Нас выстроили в очередь к нашему столу, и каждый человек занял свое место. Это было не просто темно, но вы не могли видеть что-то прямо перед вашим лицом.
#
# Официанты / официантки все были слепыми и позволили нам увидеть, насколько хорошо вам нужно быть без зрения.
#
# Утверждается, что отнятие одного чувства усиливает другие ваши чувства, в том числе вкус и слух, что, как я полагал, было верным в этом опыте.
#
# Еда была очень вкусной. У меня была курица, и она была приготовлена ​​идеально. Еще у меня было пиво-сюрприз, что было приятным сюрпризом.
#
# Этот опыт был непохож на все, что я когда-либо делал, и я надеюсь, что это распространится на другие города.
#
# Обязательно!
#
# ОТРИЦАТЕЛЬНО: они не будут записывать новых пациентов на прием в тот же день. Моя собака заболела,
# но это не обязательно срочно, поэтому я спросил, когда я смогу записаться на прием, и мне сказали, что «новые
# пациенты записываются как минимум за 6 недель вперед», так что просто предупреждайте, что это похоже на отличного
# ветеринара из других отзывов но в их системе будет сложно узнать



# Шаг 5: Оцените модель
# Реализуйте функцию, оценивающую модель TextCategorizer. Эта функция оценивает модель вместе с текстами и метками.
# Он возвращает точность модели, которая представляет собой количество правильных прогнозов, разделенное на все
# прогнозы.
#
# Во-первых, используйте метод прогнозирования, который вы написали ранее, чтобы получить прогнозируемый класс для
# каждого текста в текстах. Затем найдите, где предсказанные метки соответствуют истинным меткам «золотого
# стандарта», и рассчитайте точность.
    def evaluate(model, texts, labels):
        # Get predictions from textcat model
        predicted_class = predict(model, texts)

        # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)
        true_class = [int(each['cats']['POSITIVE']) for each in labels]

        # A boolean or int array indicating correct predictions
        correct_predictions = predicted_class == true_class

        # The accuracy, number of correct predictions divided by all predictions
        accuracy = correct_predictions.mean()

        return accuracy

accuracy = evaluate(nlp, val_texts, val_labels)
print(f"Accuracy: {accuracy:.4f}")

# This may take a while to run!
n_iters = 5
for i in range(n_iters):
    losses = train(nlp, train_data, optimizer)
    accuracy = evaluate(nlp, val_texts, val_labels)
    print(f"Loss: {losses['textcat']:.3f} \t Accuracy: {accuracy:.3f}")


# Шаг 6. Продолжайте совершенствоваться
# Вы создали необходимые компоненты для обучения классификатора текста с помощью spaCy. Что вы могли бы сделать
# дальше для оптимизации модели? 
# Выполните следующую строку, чтобы проверить свой ответ.




